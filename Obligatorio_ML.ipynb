{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entorno (Pre-Requisitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in ./.venv/lib/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: utm in ./.venv/lib/python3.12/site-packages (0.8.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.5)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.12/site-packages (7.1.0)\n",
      "Requirement already satisfied: Jinja2 in ./.venv/lib/python3.12/site-packages (3.1.6)\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.12/site-packages (5.1.2)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: GPUtil in ./.venv/lib/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (9.8.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./.venv/lib/python3.12/site-packages (from ipykernel) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=25 in ./.venv/lib/python3.12/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.12/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (9.8.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./.venv/lib/python3.12/site-packages (from ipykernel) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=25 in ./.venv/lib/python3.12/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.12/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from Jinja2) (3.0.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from Jinja2) (3.0.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unidecode utm pandas numpy matplotlib seaborn joblib scikit-learn ipykernel Jinja2 sentence-transformers ipywidgets unidecode GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Para gr√°ficos estad√≠sticos\n",
    "from jinja2 import Environment, BaseLoader # Para generaci√≥n de informes\n",
    "import os\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import utm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKtpYuuTY0iQ",
    "outputId": "5952494a-6e2b-49df-8346-606a98a164ff"
   },
   "outputs": [],
   "source": [
    "# Indicador para saber si se est√° trabajando en Google Drive\n",
    "is_Drive = False\n",
    "\n",
    "# Ruta base donde se guardar√°n o cargar√°n los archivos\n",
    "base_path = ''\n",
    "img_folder_path = \"Informe/img\"\n",
    "tex_folder_path = \"Informe/tex\"\n",
    "\n",
    "# Si estamos trabajando en Google Drive, ejecutar este bloque\n",
    "if (is_Drive):\n",
    "    from google.colab import drive, files # type: ignore\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    base_path = '/content/drive/MyDrive/Machine_Learning_Para_Sistemas_Inteligentes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_luxury = (\n",
    "    \"luxury luxe lujo premium exclusive exclusivo high-end alta gama \"\n",
    "    \"boutique designer dise√±o exklusiv \"\n",
    "    \"lavish opulent elegant posh prestigious affluent sophisticated \"\n",
    "    \"sumptuous elite grand luxurious palatial glamorous chic refined stylish \"\n",
    "    \"vintage 'designer brand' 'exclusive access'\"\n",
    ")\n",
    "\n",
    "target_studio = (\n",
    "    \"studio estudio monoambiente loft microstudio small flat tiny apartment \"\n",
    "    \"compact living microapartamento 'espacio reducido' 'estudio funcional' \"\n",
    "    \"estudio compacto 'apartamento peque√±o' 'mini loft' 'smart apartment' \"\n",
    "    \"minimalista 'apartamento de dise√±o' 'smart living' 'living space' \"\n",
    "    \"open-plan 'one-bedroom apartment' 'space-saving' compact apartment \"\n",
    "    \"cozy apartment 'minimalist studio'\"\n",
    ")\n",
    "\n",
    "target_room = (\n",
    "    \"room habitacion quarto chambre cuarto 'private room' 'shared room' \"\n",
    "    \"small room dormitorio habitaci√≥n habit√°culo 'habitaci√≥n privada' \"\n",
    "    \"'habitaci√≥n compartida' estancia 'cuarto peque√±o' suite bedroom \"\n",
    "    \"'room with a view' 'single room' 'shared space' 'personal space' \"\n",
    "    \"'living quarters' 'guest room' 'room for rent' 'co-living space' \"\n",
    "    \"'private suite'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todos Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explorar_df(df):\n",
    "    \"\"\"Imprime shape, head, info, describe e informaci√≥n de nulos de un DataFrame.\"\"\"\n",
    "    print(df.shape)\n",
    "    display(df.head())\n",
    "    print(df.info())\n",
    "    print(df.describe())\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(lati1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calcula la distancia euclidiana en metros entre puntos usando proyecci√≥n UTM.\n",
    "    Soporta inputs escalares o Series/Listas de coordenadas.\n",
    "    lat2, lon2 se asumen como el punto de referencia (escalar).\n",
    "    \"\"\"\n",
    "    # Convertir punto de referencia (landmark) a UTM\n",
    "    x_2, y_2 = utm.from_latlon(lat2, lon2)[:2]\n",
    "    \n",
    "    # Verificar si lati1 es iterable (Series, array, lista)\n",
    "    if hasattr(lati1, '__iter__') and not isinstance(lati1, str):\n",
    "        # Iterar sobre las coordenadas para convertir a UTM una por una\n",
    "        utm_coords = [utm.from_latlon(lat, lon)[:2] for lat, lon in zip(lati1, lon1)]\n",
    "        \n",
    "        # Separar en arrays numpy para c√°lculo vectorizado de distancia\n",
    "        x_1 = np.array([c[0] for c in utm_coords])\n",
    "        y_1 = np.array([c[1] for c in utm_coords])\n",
    "    else:\n",
    "        # Caso escalar\n",
    "        x_1, y_1 = utm.from_latlon(lati1, lon1)[:2]\n",
    "        \n",
    "    return np.sqrt((x_2 - x_1) ** 2 + (y_2 - y_1) ** 2)\n",
    "\n",
    "def IQR_outlier_removal(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            # Recortamos los valores extremos al rango [lower, upper]\n",
    "            df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "    return df\n",
    "\n",
    "def winsorize_outlier_removal(df, columns, lower_percentile=0.01, upper_percentile=0.99):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            lower = df[col].quantile(lower_percentile)\n",
    "            upper = df[col].quantile(upper_percentile)\n",
    "            df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, price_map=None):\n",
    "    \n",
    "    # 1. Tratamiento de valores faltantes\n",
    "    df[\"never_reviewed\"] = df[\"last_review\"].isna().astype(int)\n",
    "    df[\"reviews_per_month\"] = df[\"reviews_per_month\"].fillna(0)\n",
    "    \n",
    "    # Convertir last_review a datetime y crear days_since_last_review\n",
    "    df[\"last_review\"] = pd.to_datetime(df[\"last_review\"], errors=\"coerce\")\n",
    "    df[\"days_since_last_review\"] = (pd.Timestamp(\"today\") - df[\"last_review\"]).dt.days\n",
    "    df[\"days_since_last_review\"] = df[\"days_since_last_review\"].fillna(df[\"days_since_last_review\"].max())\n",
    "\n",
    "    # 2. Features NLP mejoradas\n",
    "    df[\"name\"] = df[\"name\"].fillna(\"\").astype(str)\n",
    "    df['name_clean'] = df['name'].str.lower().apply(unidecode.unidecode)\n",
    "\n",
    "    # NPL\n",
    "    # Se intenta identificar conceptos de lujo, studio y room mediante embeddings\n",
    "    model_st = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    name_embeddings = model_st.encode(df['name_clean'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "    emb_luxury =  model_st.encode(target_luxury, convert_to_tensor=True)\n",
    "    emb_studio = model_st.encode(target_studio, convert_to_tensor=True)\n",
    "    emb_room = model_st.encode(target_room, convert_to_tensor=True)\n",
    "\n",
    "    luxury_sim = util.cos_sim(name_embeddings, emb_luxury).cpu().numpy().flatten()\n",
    "    studio_sim = util.cos_sim(name_embeddings, emb_studio).cpu().numpy().flatten()\n",
    "    room_sim = util.cos_sim(name_embeddings, emb_room).cpu().numpy().flatten()\n",
    "\n",
    "    df[\"sim_luxury\"] = luxury_sim.astype(float)\n",
    "    df[\"sim_studio\"] = studio_sim.astype(float)\n",
    "    df[\"sim_room\"] = room_sim.astype(float)\n",
    "\n",
    "\n",
    "    # 3. Transformaciones log\n",
    "    df[\"minimum_nights_log\"] = np.log1p(df[\"minimum_nights\"])\n",
    "    df[\"number_of_reviews_log\"] = np.log1p(df[\"number_of_reviews\"])\n",
    "    df[\"availability_365_log\"] = np.log1p(df[\"availability_365\"])\n",
    "    df[\"calculated_host_listings_count_log\"] = np.log1p(df[\"calculated_host_listings_count\"])\n",
    "    \n",
    "    # Solo aplicar log al precio si existe (en train)\n",
    "    if \"price\" in df.columns:\n",
    "        df[\"price_log\"] = np.log1p(df[\"price\"])\n",
    "\n",
    "    # 4. Distancia a puntos de inter√©s \n",
    "    obelisco_lat, obelisco_lon = -34.6037, -58.3816\n",
    "\n",
    "    df[\"distance_to_obelisco\"] = distancia(df[\"latitude\"], df[\"longitude\"], obelisco_lat, obelisco_lon)\n",
    "\n",
    "    # 5. Precio por media del barrio\n",
    "    if price_map is None:\n",
    "        if \"price\" in df.columns:\n",
    "            # Calcular el precio medio por barrio\n",
    "            precio_medio_barrio = df.groupby('neighbourhood')['price'].mean().to_dict()\n",
    "            # Aplicar log\n",
    "            precio_medio_barrio = {k: np.log1p(v) for k, v in precio_medio_barrio.items()}\n",
    "        else:\n",
    "            # Fallback si no hay precio ni mapa (no deber√≠a ocurrir en flujo correcto)\n",
    "            precio_medio_barrio = {}\n",
    "    else:\n",
    "        precio_medio_barrio = price_map\n",
    "\n",
    "    # Mapear el precio medio a cada fila del DataFrame\n",
    "    df['precio_medio_barrio'] = df['neighbourhood'].map(precio_medio_barrio)\n",
    "    \n",
    "    # Rellenar nulos (barrios nuevos en test) con la media global del mapa\n",
    "    if len(precio_medio_barrio) > 0:\n",
    "        global_mean = np.mean(list(precio_medio_barrio.values()))\n",
    "        df['precio_medio_barrio'] = df['precio_medio_barrio'].fillna(global_mean)\n",
    "\n",
    "    # 6. Eliminaci√≥n de columnas innecesarias\n",
    "    df = df.drop(columns=[\"id\", \"name\", \"name_clean\", \"host_name\", \"host_id\", \"price\", \"minimum_nights\",\n",
    "                          \"number_of_reviews\", \"availability_365\", \"calculated_host_listings_count\"],\n",
    "                 errors='ignore')\n",
    "\n",
    "    return df, precio_medio_barrio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Formateo num√©rico simplificado\n",
    "# ---------------------------\n",
    "def smart_format(v):\n",
    "    if pd.isna(v):\n",
    "        return \"\"\n",
    "    s = f\"{v:.4f}\"\n",
    "    entero, dec = s.split(\".\")\n",
    "    dec = dec.rstrip(\"0\")\n",
    "    return entero if dec == \"\" else f\"{entero}.{dec}\"\n",
    "\n",
    "# ---------------------------\n",
    "# Escapes LaTeX simplificados\n",
    "# ---------------------------\n",
    "def latex_escape_header(s):\n",
    "    s = str(s).replace(\"_\", r\"\\_\\allowbreak \")\n",
    "    return fr\"\\texttt{{{s}}}\"\n",
    "\n",
    "def latex_escape_row_label(s):\n",
    "    return str(s).replace(\"_\", r\"\\_\").replace(\"%\", r\"\\%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Generador de tabla LaTeX\n",
    "# ---------------------------\n",
    "def generar_tabla_descriptiva_latex(\n",
    "    df,\n",
    "    cols,\n",
    "    percentiles,\n",
    "    output_path,\n",
    "    filename,\n",
    "    caption,\n",
    "    label,\n",
    "    incluir_varianza=True\n",
    "):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Filtrar columnas que existen en el DataFrame\n",
    "    valid_cols = [c for c in cols if c in df.columns]\n",
    "    \n",
    "    if len(valid_cols) < len(cols):\n",
    "        missing = set(cols) - set(valid_cols)\n",
    "        print(f\"[INFO] Columna {filename} (no existen en el DF): {missing}\")\n",
    "    \n",
    "\n",
    "\n",
    "    # describe()\n",
    "    desc = df[valid_cols].describe(percentiles=percentiles)\n",
    "\n",
    "    # varianza opcional\n",
    "    if incluir_varianza:\n",
    "        variance = df[valid_cols].var().rename(\"variance\")\n",
    "        desc = pd.concat([desc, variance.to_frame().T])\n",
    "\n",
    "    # encabezados\n",
    "    cols_escaped = [latex_escape_header(c) for c in desc.columns]\n",
    "\n",
    "    # filas\n",
    "    rows = [\n",
    "        (\n",
    "            latex_escape_row_label(idx),\n",
    "            [smart_format(desc.loc[idx, c]) for c in desc.columns]\n",
    "        )\n",
    "        for idx in desc.index\n",
    "    ]\n",
    "\n",
    "    # plantilla LaTeX simplificada\n",
    "    template_str = r\"\"\"\n",
    "\\begin{table}[H]\n",
    "    \\centering\n",
    "    \\setlength{\\tabcolsep}{3pt}\n",
    "    \\begin{scriptsize}\n",
    "    \\begin{adjustbox}{width=\\textwidth}\n",
    "    \\begin{tabular}{l{% for _ in cols %}r{% endfor %}}\n",
    "        \\toprule\n",
    "        & {% for col in cols %}{{ col }}{% if not loop.last %} & {% endif %}{% endfor %} \\\\\n",
    "        \\midrule\n",
    "        {% for row_label, values in rows %}\n",
    "        {{ row_label }} & {% for val in values %}{{ val }}{% if not loop.last %} & {% endif %}{% endfor %} \\\\\n",
    "        {% endfor %}\n",
    "        \\bottomrule\n",
    "    \\end{tabular}\n",
    "    \\end{adjustbox}\n",
    "    \\end{scriptsize}\n",
    "    \\caption{ {{ caption }} }\n",
    "    \\label{ {{ label }} }\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "    template = Environment(loader=BaseLoader(), autoescape=False).from_string(template_str)\n",
    "    latex_table = template.render(cols=cols_escaped, rows=rows, caption=caption, label=label)\n",
    "\n",
    "    # elimina espacios extra dentro de \\label{}\n",
    "    latex_table = re.sub(r'\\\\label\\{\\s*(.*?)\\s*\\}', r'\\\\label{\\1}', latex_table)\n",
    "\n",
    "    filepath = os.path.join(output_path, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "    print(\"Archivo LaTeX generado:\", filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_histogramas(df, df_name, base_path, folder_name=\"histogramas\", bins=50):\n",
    "\n",
    "    # Crear path final\n",
    "    output_dir = os.path.join(base_path, folder_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"[INFO] Guardando histogramas en: {output_dir}\")\n",
    "\n",
    "    # Seleccionar columnas num√©ricas\n",
    "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.histplot(df[col], bins=bins, kde=True)\n",
    "        plt.title(f\"Histograma de {col} ({df_name})\")\n",
    "\n",
    "        # Nombre del archivo incluye el nombre del dataframe\n",
    "        filename = f\"{col}_{df_name}_histograma_bins{bins}.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"   ‚Üí Guardado: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_histogramas(df, df_name, base_path, folder_name=\"histogramas\", bins=50):\n",
    "    \n",
    "    # Crear path final\n",
    "    output_dir = os.path.join(base_path, folder_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for col in df.select_dtypes(include=\"number\").columns:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.histplot(df[col], bins=bins, kde=True)\n",
    "        plt.title(f\"{col} ({df_name})\")\n",
    "\n",
    "        fname = f\"{col}_{df_name}_histograma_bins{bins}.png\"\n",
    "        plt.savefig(os.path.join(output_dir, fname), dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(\"‚Üí Guardado:\", os.path.join(output_dir, fname))\n",
    "\n",
    "\n",
    "\n",
    "def plot_percentiles_all_methods(\n",
    "    numeric_cols,\n",
    "    dfs,\n",
    "    labels,\n",
    "    percentiles=None,\n",
    "    output_dir=\"Informe/img/percentiles\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera y guarda gr√°ficos de percentiles para cada columna y cada m√©todo.\n",
    "    El archivo se guarda como:\n",
    "    img/percentiles/{col}_percentiles_max=YYY_min=XXX.png\n",
    "    donde YYY y XXX son los percentiles m√°ximo y m√≠nimo evaluados.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if percentiles is None:\n",
    "        percentiles = [90, 95, 97, 98, 99, 99.5, 99.9]\n",
    "\n",
    "    q = [p / 100.0 for p in percentiles]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "\n",
    "        if not any(col in df.columns for df in dfs):\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        for df_tmp, label in zip(dfs, labels):\n",
    "\n",
    "            if col not in df_tmp.columns:\n",
    "                continue\n",
    "\n",
    "            series = df_tmp[col].dropna()\n",
    "            if series.empty:\n",
    "                continue\n",
    "\n",
    "            p_vals = series.quantile(q)\n",
    "            plt.plot(percentiles, p_vals.values, marker=\"o\", label=label)\n",
    "\n",
    "        # Etiquetas\n",
    "        plt.xlabel(\"Percentil\")\n",
    "        plt.ylabel(col)\n",
    "        plt.title(f\"Comparaci√≥n de m√©todos en percentiles de {col}\")\n",
    "        plt.xticks(percentiles, [f\"{p}%\" for p in percentiles])\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Crear filename con el percentil m√°ximo y m√≠nimo (no los valores)\n",
    "        max_p = max(percentiles)\n",
    "        min_p = min(percentiles)\n",
    "\n",
    "        filename = f\"{col}_percentiles_max={max_p}_min={min_p}.png\"\n",
    "        # Si quisieras formato flotante fijo:\n",
    "        # filename = f\"{col}_percentiles_max={max_p:.1f}_min={min_p:.1f}.png\"\n",
    "\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Guardado: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df_to_latex(\n",
    "    df,\n",
    "    filename,\n",
    "    caption,\n",
    "    label,\n",
    "    base_path=\"Informe/tex\",\n",
    "    folder_name=\"tables\",\n",
    "    float_format=\"%.4f\",\n",
    "    big=False\n",
    "):\n",
    "\n",
    "    # Crear directorio final\n",
    "    output_dir = os.path.join(base_path, folder_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Convertir a LaTeX con escaping seguro\n",
    "    tex_body = df.to_latex(\n",
    "        index=False,\n",
    "        float_format=float_format,\n",
    "        escape=True,     # evita errores con \"_\"\n",
    "        caption=None,\n",
    "        label=None\n",
    "    )\n",
    "\n",
    "    # Plantillas simplificadas\n",
    "    if not big:\n",
    "        template = rf\"\"\"\n",
    "\\begin{{table}}[H]\n",
    "\\centering\n",
    "{tex_body}\n",
    "\\caption{{{caption}}}\n",
    "\\label{{{label}}}\n",
    "\\end{{table}}\n",
    "\"\"\"\n",
    "    else:\n",
    "        template = rf\"\"\"\n",
    "\\begin{{table}}[H]\n",
    "\\centering\n",
    "\\setlength{{\\tabcolsep}}{{4pt}}\n",
    "\\begin{{scriptsize}}\n",
    "\\begin{{adjustbox}}{{width=\\textwidth}}\n",
    "{tex_body}\n",
    "\\end{{adjustbox}}\n",
    "\\end{{scriptsize}}\n",
    "\\caption{{{caption}}}\n",
    "\\label{{{label}}}\n",
    "\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "    # Guardar archivo\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(template)\n",
    "\n",
    "    print(\"‚Üí LaTeX generado:\", filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_result = tune_and_report()\n",
    "#rf_result[\"cv_summary\"]      # DataFrame ordenado por rmse_mean\n",
    "#rf_result[\"metrics_val\"]     # m√©tricas en validaci√≥n\n",
    "#rf_result[\"best_estimator\"]  # mejor pipeline listo para usar/predicci√≥n\n",
    "\n",
    "def tune_and_report(\n",
    "    name,\n",
    "    model,\n",
    "    param_grid,\n",
    "    preprocessor,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    export_latex=False,\n",
    "    latex_filename=None,\n",
    "    latex_caption=None,\n",
    "    latex_label=None,\n",
    "    latex_dir=\"Informe/tex/tables\",\n",
    "    bigTable=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Realiza GridSearchCV, imprime m√©tricas, devuelve resumen y best model.\n",
    "    Opcionalmente exporta la tabla en LaTeX.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nüîç Optimizando {name}...\\n\")\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # ---- CV Results ----\n",
    "    cv = pd.DataFrame(grid.cv_results_)\n",
    "    cv[\"rmse_mean\"] = -cv[\"mean_test_score\"]\n",
    "    cv[\"rmse_std\"] = cv[\"std_test_score\"]\n",
    "    cv[\"MSE_mean\"] = cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "    # Selecciona autom√°ticamente las columnas de hiperpar√°metros\n",
    "    param_cols = [c for c in cv.columns if c.startswith(\"param_\")]\n",
    "\n",
    "    summary_cols = param_cols + [\"rmse_mean\", \"rmse_std\", \"MSE_mean\"]\n",
    "    summary = cv[summary_cols].sort_values(\"rmse_mean\")\n",
    "\n",
    "    print(\"üëâ Mejor params:\", grid.best_params_)\n",
    "    print(\"üëâ Mejor RMSE (CV):\", -grid.best_score_)\n",
    "\n",
    "    # ---- M√©tricas en validaci√≥n ----\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"üìå {name} (validaci√≥n) -> RMSE={rmse:.3f}, MSE={mse:.3f}, MAE={mae:.3f}, R2={r2:.3f}\")\n",
    "\n",
    "    # ---- Exportar LaTeX (opcional) ----\n",
    "    if export_latex:\n",
    "        export_df_to_latex(\n",
    "            df=summary,\n",
    "            filename=latex_filename,\n",
    "            caption=latex_caption,\n",
    "            label=latex_label,\n",
    "            base_path=latex_dir,\n",
    "            folder_name=\"\",\n",
    "            big=bigTable\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"best_estimator\": best_model,\n",
    "        \"cv_summary\": summary,\n",
    "        \"metrics_val\": {\n",
    "            \"rmse\": rmse,\n",
    "            \"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            r\"R^{2}\": r2\n",
    "        }\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_models(\n",
    "    models_dict,\n",
    "    X,\n",
    "    y,\n",
    "    preprocessor=None,\n",
    "    cv_folds=5,\n",
    "    export_latex=False,\n",
    "    latex_filename=\"cv_results.tex\",\n",
    "    latex_caption=\"Resultados de validaci√≥n cruzada (CV).\",\n",
    "    latex_label=\"tab:cv-all-models\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta validaci√≥n cruzada para m√∫ltiples modelos.\n",
    "    Devuelve un DataFrame con rmse, mse, mae y r2 promedio.\n",
    "    Si export_latex=True exporta tabla para LaTeX.\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_results = []\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        print(f\"‚Üí Ejecutando CV para: {name}\")\n",
    "\n",
    "        # Si ya viene como Pipeline, lo usamos tal cual\n",
    "        # Si no, lo envolvemos con el preprocessor\n",
    "        pipe = model if isinstance(model, Pipeline) else Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        # RMSE (negativo de sklearn)\n",
    "        rmse_scores = -cross_val_score(\n",
    "            pipe, X, y,\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=kf, n_jobs=-1\n",
    "        )\n",
    "        mse_scores = rmse_scores ** 2\n",
    "\n",
    "        # MAE\n",
    "        mae_scores = -cross_val_score(\n",
    "            pipe, X, y,\n",
    "            scoring=\"neg_mean_absolute_error\",\n",
    "            cv=kf, n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # R¬≤\n",
    "        r2_scores = cross_val_score(\n",
    "            pipe, X, y,\n",
    "            scoring=\"r2\",\n",
    "            cv=kf, n_jobs=-1\n",
    "        )\n",
    "\n",
    "        cv_results.append({\n",
    "            \"Modelo\": name,\n",
    "            \"rmse_mean\": rmse_scores.mean(),\n",
    "            \"rmse_std\": rmse_scores.std(),\n",
    "            \"MSE_mean\": mse_scores.mean(),\n",
    "            \"MAE_mean\": mae_scores.mean(),\n",
    "            \"R2_mean\": r2_scores.mean(),\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(cv_results).sort_values(by=\"rmse_mean\")\n",
    "\n",
    "    display(df_results)\n",
    "\n",
    "    # Exportar a LaTeX si corresponde\n",
    "    if export_latex:\n",
    "        export_df_to_latex(\n",
    "            df_results,\n",
    "            filename=latex_filename,\n",
    "            caption=latex_caption,\n",
    "            label=latex_label,\n",
    "            base_path=\"Informe/tex\",\n",
    "            folder_name=\"tables\",\n",
    "            big=True\n",
    "        )\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos(models, preprocessor, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_pred = pipe.predict(X_val)\n",
    "\n",
    "            mse  = mean_squared_error(y_val, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae  = mean_absolute_error(y_val, y_pred)\n",
    "            r2   = r2_score(y_val, y_pred)\n",
    "\n",
    "            resultados.append({\n",
    "                \"Modelo\": name,\n",
    "                \"RMSE\": rmse,\n",
    "                \"MSE\": mse,\n",
    "                \"MAE\": mae,\n",
    "                r\"R^{2}\": r2,\n",
    "            })\n",
    "\n",
    "            print(f\"{name:<20} RMSE={rmse:7.3f} | MSE={mse:7.3f} | MAE={mae:7.3f} | R2={r2:7.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] El modelo '{name}' fall√≥: {e}\")\n",
    "            resultados.append({\n",
    "                \"Modelo\": name,\n",
    "                \"RMSE\": np.nan,\n",
    "                \"MSE\": np.nan,\n",
    "                \"MAE\": np.nan,\n",
    "                r\"R^{2}\": np.nan,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7279fc17"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "U-uUWi9KEHzW",
    "outputId": "b174182a-85c6-49e6-d597-0f00a44d5ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando datos...\")\n",
    "df_raw_train = pd.read_csv(base_path + \"train.csv\")\n",
    "df_raw_test = pd.read_csv(base_path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzzGsDY8EUFH",
    "outputId": "8e276899-00e8-4327-f87e-b0c080c9875b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informaci√≥n sobre train.csv: \n",
      "\n",
      "(6864, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15843708</td>\n",
       "      <td>Monoambiente en Barrio Norte</td>\n",
       "      <td>19787638</td>\n",
       "      <td>Pablo</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>-34.59053</td>\n",
       "      <td>-58.40898</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>03-11-2019</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9735218</td>\n",
       "      <td>Busco Roomate :)</td>\n",
       "      <td>38507726</td>\n",
       "      <td>Angela</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>-34.58633</td>\n",
       "      <td>-58.41312</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35682605</td>\n",
       "      <td>Betty¬¥s home</td>\n",
       "      <td>100972248</td>\n",
       "      <td>Cecilia</td>\n",
       "      <td>Balvanera</td>\n",
       "      <td>-34.59979</td>\n",
       "      <td>-58.39340</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>03-11-2019</td>\n",
       "      <td>2.67</td>\n",
       "      <td>5</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9473906</td>\n",
       "      <td>Lovely Studio in Palermo</td>\n",
       "      <td>25602761</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>-34.59395</td>\n",
       "      <td>-58.41423</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>21-11-2019</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34155238</td>\n",
       "      <td>Cozy and comfortable apartment in Belgrano.</td>\n",
       "      <td>128766227</td>\n",
       "      <td>Maite</td>\n",
       "      <td>Colegiales</td>\n",
       "      <td>-34.56911</td>\n",
       "      <td>-58.45162</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10-11-2019</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         name    host_id host_name  \\\n",
       "0  15843708                 Monoambiente en Barrio Norte   19787638     Pablo   \n",
       "1   9735218                             Busco Roomate :)   38507726    Angela   \n",
       "2  35682605                                 Betty¬¥s home  100972248   Cecilia   \n",
       "3   9473906                     Lovely Studio in Palermo   25602761   Mariano   \n",
       "4  34155238  Cozy and comfortable apartment in Belgrano.  128766227     Maite   \n",
       "\n",
       "  neighbourhood  latitude  longitude        room_type  minimum_nights  \\\n",
       "0      Recoleta -34.59053  -58.40898  Entire home/apt               2   \n",
       "1       Palermo -34.58633  -58.41312     Private room               1   \n",
       "2     Balvanera -34.59979  -58.39340  Entire home/apt               3   \n",
       "3      Recoleta -34.59395  -58.41423  Entire home/apt               3   \n",
       "4    Colegiales -34.56911  -58.45162  Entire home/apt               2   \n",
       "\n",
       "   number_of_reviews last_review  reviews_per_month  \\\n",
       "0                 26  03-11-2019               0.90   \n",
       "1                  0         NaN                NaN   \n",
       "2                  4  03-11-2019               2.67   \n",
       "3                 43  21-11-2019               0.89   \n",
       "4                 13  10-11-2019               2.12   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               1                74  \n",
       "1                               1                 0  \n",
       "2                               5               270  \n",
       "3                               1               142  \n",
       "4                               1               241  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6864 entries, 0 to 6863\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              6864 non-null   int64  \n",
      " 1   name                            6862 non-null   object \n",
      " 2   host_id                         6864 non-null   int64  \n",
      " 3   host_name                       6854 non-null   object \n",
      " 4   neighbourhood                   6864 non-null   object \n",
      " 5   latitude                        6864 non-null   float64\n",
      " 6   longitude                       6864 non-null   float64\n",
      " 7   room_type                       6864 non-null   object \n",
      " 8   minimum_nights                  6864 non-null   int64  \n",
      " 9   number_of_reviews               6864 non-null   int64  \n",
      " 10  last_review                     4969 non-null   object \n",
      " 11  reviews_per_month               4969 non-null   float64\n",
      " 12  calculated_host_listings_count  6864 non-null   int64  \n",
      " 13  availability_365                6864 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(5)\n",
      "memory usage: 750.9+ KB\n",
      "None\n",
      "                 id       host_id     latitude    longitude  minimum_nights  \\\n",
      "count  6.864000e+03  6.864000e+03  6864.000000  6864.000000     6864.000000   \n",
      "mean   2.490761e+07  9.896970e+07   -34.592594   -58.416503        5.953526   \n",
      "std    1.185853e+07  9.340289e+07     0.018250     0.030125       24.854020   \n",
      "min    7.270000e+03  1.882200e+04   -34.685750   -58.529290        1.000000   \n",
      "25%    1.631949e+07  1.449728e+07   -34.603540   -58.435645        1.000000   \n",
      "50%    2.854466e+07  6.396147e+07   -34.591690   -58.416145        3.000000   \n",
      "75%    3.457301e+07  1.733172e+08   -34.581967   -58.392130        4.000000   \n",
      "max    4.035182e+07  3.118884e+08   -34.532720   -58.358190     1125.000000   \n",
      "\n",
      "       number_of_reviews  reviews_per_month  calculated_host_listings_count  \\\n",
      "count        6864.000000        4969.000000                     6864.000000   \n",
      "mean           15.968094           1.287790                        6.091346   \n",
      "std            32.450206           1.543534                       14.278927   \n",
      "min             0.000000           0.010000                        1.000000   \n",
      "25%             0.000000           0.260000                        1.000000   \n",
      "50%             4.000000           0.760000                        1.000000   \n",
      "75%            17.000000           1.850000                        4.000000   \n",
      "max           600.000000          37.580000                      105.000000   \n",
      "\n",
      "       availability_365  \n",
      "count       6864.000000  \n",
      "mean         201.211976  \n",
      "std          134.101514  \n",
      "min            0.000000  \n",
      "25%           83.000000  \n",
      "50%          180.000000  \n",
      "75%          343.000000  \n",
      "max          365.000000  \n",
      "id                                   0\n",
      "name                                 2\n",
      "host_id                              0\n",
      "host_name                           10\n",
      "neighbourhood                        0\n",
      "latitude                             0\n",
      "longitude                            0\n",
      "room_type                            0\n",
      "minimum_nights                       0\n",
      "number_of_reviews                    0\n",
      "last_review                       1895\n",
      "reviews_per_month                 1895\n",
      "calculated_host_listings_count       0\n",
      "availability_365                     0\n",
      "dtype: int64\n",
      " \n",
      " \n",
      " Informaci√≥n sobre test.csv: \n",
      "\n",
      "(6864, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15843708</td>\n",
       "      <td>Monoambiente en Barrio Norte</td>\n",
       "      <td>19787638</td>\n",
       "      <td>Pablo</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>-34.59053</td>\n",
       "      <td>-58.40898</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>03-11-2019</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9735218</td>\n",
       "      <td>Busco Roomate :)</td>\n",
       "      <td>38507726</td>\n",
       "      <td>Angela</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>-34.58633</td>\n",
       "      <td>-58.41312</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35682605</td>\n",
       "      <td>Betty¬¥s home</td>\n",
       "      <td>100972248</td>\n",
       "      <td>Cecilia</td>\n",
       "      <td>Balvanera</td>\n",
       "      <td>-34.59979</td>\n",
       "      <td>-58.39340</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>03-11-2019</td>\n",
       "      <td>2.67</td>\n",
       "      <td>5</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9473906</td>\n",
       "      <td>Lovely Studio in Palermo</td>\n",
       "      <td>25602761</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>-34.59395</td>\n",
       "      <td>-58.41423</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>21-11-2019</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34155238</td>\n",
       "      <td>Cozy and comfortable apartment in Belgrano.</td>\n",
       "      <td>128766227</td>\n",
       "      <td>Maite</td>\n",
       "      <td>Colegiales</td>\n",
       "      <td>-34.56911</td>\n",
       "      <td>-58.45162</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10-11-2019</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         name    host_id host_name  \\\n",
       "0  15843708                 Monoambiente en Barrio Norte   19787638     Pablo   \n",
       "1   9735218                             Busco Roomate :)   38507726    Angela   \n",
       "2  35682605                                 Betty¬¥s home  100972248   Cecilia   \n",
       "3   9473906                     Lovely Studio in Palermo   25602761   Mariano   \n",
       "4  34155238  Cozy and comfortable apartment in Belgrano.  128766227     Maite   \n",
       "\n",
       "  neighbourhood  latitude  longitude        room_type  minimum_nights  \\\n",
       "0      Recoleta -34.59053  -58.40898  Entire home/apt               2   \n",
       "1       Palermo -34.58633  -58.41312     Private room               1   \n",
       "2     Balvanera -34.59979  -58.39340  Entire home/apt               3   \n",
       "3      Recoleta -34.59395  -58.41423  Entire home/apt               3   \n",
       "4    Colegiales -34.56911  -58.45162  Entire home/apt               2   \n",
       "\n",
       "   number_of_reviews last_review  reviews_per_month  \\\n",
       "0                 26  03-11-2019               0.90   \n",
       "1                  0         NaN                NaN   \n",
       "2                  4  03-11-2019               2.67   \n",
       "3                 43  21-11-2019               0.89   \n",
       "4                 13  10-11-2019               2.12   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               1                74  \n",
       "1                               1                 0  \n",
       "2                               5               270  \n",
       "3                               1               142  \n",
       "4                               1               241  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6864 entries, 0 to 6863\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              6864 non-null   int64  \n",
      " 1   name                            6862 non-null   object \n",
      " 2   host_id                         6864 non-null   int64  \n",
      " 3   host_name                       6854 non-null   object \n",
      " 4   neighbourhood                   6864 non-null   object \n",
      " 5   latitude                        6864 non-null   float64\n",
      " 6   longitude                       6864 non-null   float64\n",
      " 7   room_type                       6864 non-null   object \n",
      " 8   minimum_nights                  6864 non-null   int64  \n",
      " 9   number_of_reviews               6864 non-null   int64  \n",
      " 10  last_review                     4969 non-null   object \n",
      " 11  reviews_per_month               4969 non-null   float64\n",
      " 12  calculated_host_listings_count  6864 non-null   int64  \n",
      " 13  availability_365                6864 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(5)\n",
      "memory usage: 750.9+ KB\n",
      "None\n",
      "                 id       host_id     latitude    longitude  minimum_nights  \\\n",
      "count  6.864000e+03  6.864000e+03  6864.000000  6864.000000     6864.000000   \n",
      "mean   2.490761e+07  9.896970e+07   -34.592594   -58.416503        5.953526   \n",
      "std    1.185853e+07  9.340289e+07     0.018250     0.030125       24.854020   \n",
      "min    7.270000e+03  1.882200e+04   -34.685750   -58.529290        1.000000   \n",
      "25%    1.631949e+07  1.449728e+07   -34.603540   -58.435645        1.000000   \n",
      "50%    2.854466e+07  6.396147e+07   -34.591690   -58.416145        3.000000   \n",
      "75%    3.457301e+07  1.733172e+08   -34.581967   -58.392130        4.000000   \n",
      "max    4.035182e+07  3.118884e+08   -34.532720   -58.358190     1125.000000   \n",
      "\n",
      "       number_of_reviews  reviews_per_month  calculated_host_listings_count  \\\n",
      "count        6864.000000        4969.000000                     6864.000000   \n",
      "mean           15.968094           1.287790                        6.091346   \n",
      "std            32.450206           1.543534                       14.278927   \n",
      "min             0.000000           0.010000                        1.000000   \n",
      "25%             0.000000           0.260000                        1.000000   \n",
      "50%             4.000000           0.760000                        1.000000   \n",
      "75%            17.000000           1.850000                        4.000000   \n",
      "max           600.000000          37.580000                      105.000000   \n",
      "\n",
      "       availability_365  \n",
      "count       6864.000000  \n",
      "mean         201.211976  \n",
      "std          134.101514  \n",
      "min            0.000000  \n",
      "25%           83.000000  \n",
      "50%          180.000000  \n",
      "75%          343.000000  \n",
      "max          365.000000  \n",
      "id                                   0\n",
      "name                                 2\n",
      "host_id                              0\n",
      "host_name                           10\n",
      "neighbourhood                        0\n",
      "latitude                             0\n",
      "longitude                            0\n",
      "room_type                            0\n",
      "minimum_nights                       0\n",
      "number_of_reviews                    0\n",
      "last_review                       1895\n",
      "reviews_per_month                 1895\n",
      "calculated_host_listings_count       0\n",
      "availability_365                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#info de Train\n",
    "print(\"Informaci√≥n sobre train.csv: \\n\")\n",
    "explorar_df(df_raw_test)\n",
    "\n",
    "#Info de Test\n",
    "print(\" \\n \\n Informaci√≥n sobre test.csv: \\n\")\n",
    "explorar_df(df_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KPYyhsHBEurc"
   },
   "outputs": [],
   "source": [
    "df_preprocessed_train, train_price_map = preprocess_data(df_raw_train)\n",
    "\n",
    "df_pre_IQR = IQR_outlier_removal(df_preprocessed_train.copy(), \n",
    "                                 [ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\" ,\"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"])\n",
    "\n",
    "df_pre_win = winsorize_outlier_removal(df_preprocessed_train.copy(), \n",
    "                                       [ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\" ,\"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gr√°fica de los Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/df_prepocessed_train_desc.tex\n",
      "Archivo LaTeX generado: Informe/tex/tables/df_iqr_desc.tex\n",
      "Archivo LaTeX generado: Informe/tex/tables/df_raw_train_desc.tex\n"
     ]
    }
   ],
   "source": [
    "tbl_paths = os.path.join(tex_folder_path, \"tables\");\n",
    "percent_lst = [0, 0.15, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99] \n",
    "\n",
    "generar_tabla_descriptiva_latex(\n",
    "    df=df_preprocessed_train,\n",
    "    cols=[ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\", \"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"],\n",
    "    percentiles=percent_lst,\n",
    "    output_path= tbl_paths,\n",
    "    filename=\"df_prepocessed_train_desc.tex\",\n",
    "    caption=r\"Datos estad√≠sticos pre-procesados del conjunto de entrenamiento.\",\n",
    "    label=r\"tab:df-preprocessed-train-desc\"\n",
    ")\n",
    " \n",
    "generar_tabla_descriptiva_latex(\n",
    "    df=df_pre_IQR,\n",
    "    cols=[ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\", \"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"],\n",
    "    percentiles=percent_lst,\n",
    "    output_path= tbl_paths,\n",
    "    filename=\"df_iqr_desc.tex\",\n",
    "    caption=r\"Estad√≠sticos descriptivos de las variables num√©ricas tras el tratamiento de outliers con IQR (adem√°s de aplicar \\lstinline[style=python]{np.expm1} a \\texttt{price}).\",\n",
    "    label=r\"tab:df-iqr-desc-log\"\n",
    ")\n",
    "\n",
    "generar_tabla_descriptiva_latex(\n",
    "    df=df_raw_train,\n",
    "    cols=[\"price\",\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\"calculated_host_listings_count\",\"availability_365\",\"days_since_last_review\"],\n",
    "    percentiles=percent_lst,\n",
    "    output_path= tbl_paths,\n",
    "    filename=\"df_raw_train_desc.tex\",\n",
    "    caption=r\"Datos estad√≠sticos originales del conjunto de entrenamiento.\",\n",
    "    label=r\"tab:df-raw-train-desc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Guardado: Informe/img/histogramas/id_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/host_id_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/host_id_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/latitude_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/latitude_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/longitude_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/longitude_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/reviews_per_month_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/reviews_per_month_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/never_reviewed_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/never_reviewed_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/days_since_last_review_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/days_since_last_review_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_luxury_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_luxury_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_studio_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_studio_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_room_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_room_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_log_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/distance_to_obelisco_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/distance_to_obelisco_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/precio_medio_barrio_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/precio_medio_barrio_raw_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/latitude_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/latitude_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/longitude_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/longitude_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/reviews_per_month_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/reviews_per_month_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/never_reviewed_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/never_reviewed_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/days_since_last_review_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/days_since_last_review_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_luxury_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_luxury_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_studio_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_studio_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_room_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_room_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_log_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/distance_to_obelisco_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/distance_to_obelisco_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/precio_medio_barrio_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/precio_medio_barrio_preprocessed_train_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/latitude_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/latitude_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/longitude_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/longitude_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/reviews_per_month_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/reviews_per_month_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/never_reviewed_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/never_reviewed_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/days_since_last_review_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/days_since_last_review_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_luxury_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_luxury_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_studio_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_studio_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_room_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/sim_room_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/minimum_nights_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/number_of_reviews_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/availability_365_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/calculated_host_listings_count_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/price_log_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/distance_to_obelisco_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/distance_to_obelisco_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/precio_medio_barrio_pre_IQR_histograma_bins50.png\n",
      "‚Üí Guardado: Informe/img/histogramas/precio_medio_barrio_pre_IQR_histograma_bins50.png\n"
     ]
    }
   ],
   "source": [
    "generar_histogramas(df_raw_train, \"raw_train\", img_folder_path)\n",
    "generar_histogramas(df_preprocessed_train, \"preprocessed_train\", img_folder_path)\n",
    "generar_histogramas(df_pre_IQR, \"pre_IQR\", img_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: Informe/img/percentiles/price_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/availability_365_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/availability_365_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_log_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=100_min=0.png\n",
      "Guardado: Informe/img/percentiles/price_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/price_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/availability_365_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/availability_365_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_log_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/price_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/price_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/availability_365_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/availability_365_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_log_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=12_min=0.png\n"
     ]
    }
   ],
   "source": [
    "dfs = [df_preprocessed_train, df_pre_win, df_pre_IQR]\n",
    "labels = [\"Original (sin tratamiento de outliers)\", \"Winsorize (1‚Äì99%)\", \"IQR\"]\n",
    "\n",
    "plot_percentiles_all_methods([ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\", \"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"], dfs, labels, percentiles= [0,10, 25, 50, 75, 90, 95, 100])\n",
    "plot_percentiles_all_methods([ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\", \"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"], dfs, labels, percentiles=[95, 96, 97, 98, 99, 99.5, 100])\n",
    "plot_percentiles_all_methods([ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\", \"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"], dfs, labels, percentiles=[0, 0.5 , 1, 2, 3, 4, 5, 10 ,12])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6402d288"
   },
   "source": [
    "## Split the data\n",
    "\n",
    "Split the DataFrame into training and validation sets (70% for training, 30% for validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRWIQ-MZGFss",
    "outputId": "08e8796b-89ab-41ef-a101-891b673818e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±os: (11209, 17) (4804, 17)\n"
     ]
    }
   ],
   "source": [
    "X = df_pre_IQR.drop(\"price_log\", axis=1)\n",
    "y = df_pre_IQR[\"price_log\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Tama√±os:\", X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52b7685b"
   },
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "eebdd7e2"
   },
   "outputs": [],
   "source": [
    "# Identificamos variables num√©ricas y categ√≥ricas\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Definimos transformaciones\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aaf85bd1"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"NeuralNetwork\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7760de4e"
   },
   "source": [
    "# Train the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy                RMSE=  0.732 | MSE=  0.535 | MAE=  0.572 | R2= -0.000\n",
      "LinearRegression     RMSE=  0.586 | MSE=  0.344 | MAE=  0.445 | R2=  0.358\n",
      "LinearRegression     RMSE=  0.586 | MSE=  0.344 | MAE=  0.445 | R2=  0.358\n",
      "DecisionTree         RMSE=  0.801 | MSE=  0.641 | MAE=  0.609 | R2= -0.198\n",
      "DecisionTree         RMSE=  0.801 | MSE=  0.641 | MAE=  0.609 | R2= -0.198\n",
      "RandomForest         RMSE=  0.553 | MSE=  0.306 | MAE=  0.420 | R2=  0.428\n",
      "RandomForest         RMSE=  0.553 | MSE=  0.306 | MAE=  0.420 | R2=  0.428\n",
      "GradientBoosting     RMSE=  0.565 | MSE=  0.319 | MAE=  0.431 | R2=  0.404\n",
      "GradientBoosting     RMSE=  0.565 | MSE=  0.319 | MAE=  0.431 | R2=  0.404\n",
      "NeuralNetwork        RMSE=  0.601 | MSE=  0.361 | MAE=  0.456 | R2=  0.326\n",
      "NeuralNetwork        RMSE=  0.601 | MSE=  0.361 | MAE=  0.456 | R2=  0.326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R^{2}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.731699</td>\n",
       "      <td>0.535383</td>\n",
       "      <td>0.572285</td>\n",
       "      <td>-0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.586430</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.445244</td>\n",
       "      <td>0.357589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.800934</td>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.608925</td>\n",
       "      <td>-0.198324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.553297</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.419915</td>\n",
       "      <td>0.428129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.564862</td>\n",
       "      <td>0.319069</td>\n",
       "      <td>0.431338</td>\n",
       "      <td>0.403974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.600613</td>\n",
       "      <td>0.360737</td>\n",
       "      <td>0.455906</td>\n",
       "      <td>0.326138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo      RMSE       MSE       MAE     R^{2}\n",
       "0             Dummy  0.731699  0.535383  0.572285 -0.000105\n",
       "1  LinearRegression  0.586430  0.343900  0.445244  0.357589\n",
       "2      DecisionTree  0.800934  0.641495  0.608925 -0.198324\n",
       "3      RandomForest  0.553297  0.306138  0.419915  0.428129\n",
       "4  GradientBoosting  0.564862  0.319069  0.431338  0.403974\n",
       "5     NeuralNetwork  0.600613  0.360737  0.455906  0.326138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí LaTeX generado: Informe/tex/tables/model_results_final.tex\n"
     ]
    }
   ],
   "source": [
    "# ---- Ejecutar evaluaci√≥n ----\n",
    "results_df = evaluar_modelos(models, preprocessor, X_train, y_train, X_val, y_val)\n",
    "display(results_df)\n",
    "\n",
    "# ---- Exportar a LaTeX ----\n",
    "export_df_to_latex(\n",
    "    df=results_df,\n",
    "    filename=\"model_results_final.tex\",\n",
    "    caption=\"Resultados del primer barrido de modelos sobre la partici√≥n de validaci√≥n (70/30).\",\n",
    "    label=\"tab:model-results-first-barrido\",\n",
    "    base_path=\"Informe/tex\",\n",
    "    folder_name=\"tables\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8ef3cc"
   },
   "source": [
    "## Evaluate the models\n",
    "\n",
    "Evaluate the performance of models on the validation data using appropriate metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Optimizando Lasso...\n",
      "\n",
      "üëâ Mejor params: {'model__alpha': 0.001}\n",
      "üëâ Mejor RMSE (CV): 0.589769904806074\n",
      "üìå Lasso (validaci√≥n) -> RMSE=0.584, MSE=0.342, MAE=0.445, R2=0.362\n",
      "‚Üí LaTeX generado: Informe/tex/tables/Lasso_gridsearch_results.tex\n",
      "üëâ Mejor params: {'model__alpha': 0.001}\n",
      "üëâ Mejor RMSE (CV): 0.589769904806074\n",
      "üìå Lasso (validaci√≥n) -> RMSE=0.584, MSE=0.342, MAE=0.445, R2=0.362\n",
      "‚Üí LaTeX generado: Informe/tex/tables/Lasso_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "lasso_result = tune_and_report(\n",
    "    name=\"Lasso\",\n",
    "    model=Lasso(max_iter=10000, random_state=42),\n",
    "    param_grid={\"model__alpha\": [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    preprocessor=preprocessor,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    export_latex=True,\n",
    "    latex_filename=\"Lasso_gridsearch_results.tex\",\n",
    "    latex_caption=\"Resultados del GridSearchCV para la regresi√≥n Lasso.\",\n",
    "    latex_label=\"tab:lasso-gridsearch\"\n",
    ")\n",
    "\n",
    "# Best\n",
    "optimized_models[\"Lasso Optimizado\"] = lasso_result[\"best_estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Optimizando Ridge...\n",
      "\n",
      "üëâ Mejor params: {'model__alpha': 0.1}\n",
      "üëâ Mejor RMSE (CV): 0.5883850160956631\n",
      "üìå Ridge (validaci√≥n) -> RMSE=0.586, MSE=0.344, MAE=0.445, R2=0.358\n",
      "‚Üí LaTeX generado: Informe/tex/tables/Ridge_gridsearch_results.tex\n",
      "üëâ Mejor params: {'model__alpha': 0.1}\n",
      "üëâ Mejor RMSE (CV): 0.5883850160956631\n",
      "üìå Ridge (validaci√≥n) -> RMSE=0.586, MSE=0.344, MAE=0.445, R2=0.358\n",
      "‚Üí LaTeX generado: Informe/tex/tables/Ridge_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "ridge_result = tune_and_report(\n",
    "    name=\"Ridge\",\n",
    "    model=Ridge(max_iter=10000, random_state=42),\n",
    "    param_grid={\"model__alpha\": [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    preprocessor=preprocessor,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    export_latex=True,\n",
    "    latex_filename=\"Ridge_gridsearch_results.tex\",\n",
    "    latex_caption=\"Resultados del GridSearchCV para regresi√≥n Ridge.\",\n",
    "    latex_label=\"tab:ridge-gridsearch\"\n",
    ")\n",
    "\n",
    "# Best\n",
    "optimized_models[\"Ridge Optimizado\"] = ridge_result[\"best_estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Optimizando GradientBoosting...\n",
      "\n",
      "üëâ Mejor params: {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "üëâ Mejor RMSE (CV): 0.5665823848753672\n",
      "üìå GradientBoosting (validaci√≥n) -> RMSE=0.556, MSE=0.309, MAE=0.421, R2=0.423\n",
      "‚Üí LaTeX generado: Informe/tex/tables/GradientBoosting_gridsearch_results.tex\n",
      "üëâ Mejor params: {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "üëâ Mejor RMSE (CV): 0.5665823848753672\n",
      "üìå GradientBoosting (validaci√≥n) -> RMSE=0.556, MSE=0.309, MAE=0.421, R2=0.423\n",
      "‚Üí LaTeX generado: Informe/tex/tables/GradientBoosting_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "gb_result = tune_and_report(\n",
    "    name=\"GradientBoosting\",\n",
    "    model=GradientBoostingRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        \"model__n_estimators\": [50, 100, 200],\n",
    "        \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"model__max_depth\": [3, 5, 7],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2]\n",
    "    },\n",
    "    preprocessor=preprocessor,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    export_latex=True,\n",
    "    latex_filename=\"GradientBoosting_gridsearch_results.tex\",\n",
    "    latex_caption=\"Resultados del GridSearchCV para Gradient Boosting Regressor.\",\n",
    "    latex_label=\"tab:gradient-boosting-gridsearch\",\n",
    "    bigTable=True\n",
    ")\n",
    "\n",
    "# Best\n",
    "optimized_models[\"GradientBoosting Optimizado\"] = gb_result[\"best_estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Optimizando RandomForest...\n",
      "\n",
      "üëâ Mejor params: {'model__max_depth': 20, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n",
      "üëâ Mejor RMSE (CV): 0.5702863545964417\n",
      "üìå RandomForest (validaci√≥n) -> RMSE=0.552, MSE=0.305, MAE=0.419, R2=0.431\n",
      "‚Üí LaTeX generado: Informe/tex/tables/RandomForest_gridsearch_results.tex\n",
      "üëâ Mejor params: {'model__max_depth': 20, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n",
      "üëâ Mejor RMSE (CV): 0.5702863545964417\n",
      "üìå RandomForest (validaci√≥n) -> RMSE=0.552, MSE=0.305, MAE=0.419, R2=0.431\n",
      "‚Üí LaTeX generado: Informe/tex/tables/RandomForest_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "rf_result = tune_and_report(\n",
    "    name=\"RandomForest\",\n",
    "    model=RandomForestRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        \"model__n_estimators\": [1, 50, 100, 200],\n",
    "        \"model__max_depth\": [1, 3, 5, 10, 20, None],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2],\n",
    "    },\n",
    "    preprocessor=preprocessor,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    export_latex=True,\n",
    "    latex_filename=\"RandomForest_gridsearch_results.tex\",\n",
    "    latex_caption=\"GridSearch para Random Forest.\",\n",
    "    latex_label=\"tab:random-forest\",\n",
    "    bigTable=True\n",
    ")\n",
    "\n",
    "# Best\n",
    "optimized_models[\"RandomForest Optimizado\"] = rf_result[\"best_estimator\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Optimizando DecisionTreeRegressor...\n",
      "\n",
      "üëâ Mejor params: {'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2}\n",
      "üëâ Mejor RMSE (CV): 0.6078622182068706\n",
      "üìå DecisionTreeRegressor (validaci√≥n) -> RMSE=0.600, MSE=0.360, MAE=0.458, R2=0.327\n",
      "‚Üí LaTeX generado: Informe/tex/tables/DecisionTreeRegressor_gridsearch_results.tex\n",
      "üëâ Mejor params: {'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2}\n",
      "üëâ Mejor RMSE (CV): 0.6078622182068706\n",
      "üìå DecisionTreeRegressor (validaci√≥n) -> RMSE=0.600, MSE=0.360, MAE=0.458, R2=0.327\n",
      "‚Üí LaTeX generado: Informe/tex/tables/DecisionTreeRegressor_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "dt_result = tune_and_report(\n",
    "    name=\"DecisionTreeRegressor\",\n",
    "    model=DecisionTreeRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        \"model__max_depth\": [1, 2, 3, 5, 10, 20, None],\n",
    "        \"model__min_samples_split\": [2, 5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    preprocessor=preprocessor,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    export_latex=True,\n",
    "    latex_filename=\"DecisionTreeRegressor_gridsearch_results.tex\",\n",
    "    latex_caption=\"GridSearch para Decision Tree.\",\n",
    "    latex_label=\"tab:decision-tree\",\n",
    "    bigTable=True\n",
    ")\n",
    "\n",
    "# Best\n",
    "optimized_models[\"DecisionTreeRegressor Optimizado\"] = dt_result[\"best_estimator\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Optimizando NeuralNetwork...\n",
      "\n",
      "üëâ Mejor params: {'model__alpha': 0.0001, 'model__hidden_layer_sizes': (128, 64), 'model__learning_rate_init': 0.001}\n",
      "üëâ Mejor RMSE (CV): 0.5947026743635637\n",
      "üìå NeuralNetwork (validaci√≥n) -> RMSE=0.581, MSE=0.337, MAE=0.445, R2=0.370\n",
      "‚Üí LaTeX generado: Informe/tex/tables/MLP_gridsearch_results.tex\n",
      "üëâ Mejor params: {'model__alpha': 0.0001, 'model__hidden_layer_sizes': (128, 64), 'model__learning_rate_init': 0.001}\n",
      "üëâ Mejor RMSE (CV): 0.5947026743635637\n",
      "üìå NeuralNetwork (validaci√≥n) -> RMSE=0.581, MSE=0.337, MAE=0.445, R2=0.370\n",
      "‚Üí LaTeX generado: Informe/tex/tables/MLP_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "nn_result = tune_and_report(\n",
    "    name=\"NeuralNetwork\",\n",
    "    model=MLPRegressor(\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "        early_stopping=True\n",
    "    ),\n",
    "    param_grid={\n",
    "        \"model__hidden_layer_sizes\": [(64,), (128, 64), (64, 32)],\n",
    "        \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "        \"model__learning_rate_init\": [0.001, 0.01],\n",
    "    },\n",
    "    preprocessor=preprocessor,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "\n",
    "    # export LaTeX\n",
    "    export_latex=True,\n",
    "    latex_filename=\"MLP_gridsearch_results.tex\",\n",
    "    latex_caption=\"Resultados del GridSearchCV para el modelo MLPRegressor (Neural Network).\",\n",
    "    latex_label=\"tab:mlpregressor-gridsearch\",\n",
    "    bigTable=True  # porque las NN suelen tener muchas combinaciones\n",
    ")\n",
    "\n",
    "# Guardar el mejor modelo optimizado\n",
    "optimized_models[\"NeuralNetwork Optimizado\"] = nn_result[\"best_estimator\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corss Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    **models,\n",
    "    **optimized_models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Ejecutando CV para: Dummy\n",
      "‚Üí Ejecutando CV para: LinearRegression\n",
      "‚Üí Ejecutando CV para: LinearRegression\n",
      "‚Üí Ejecutando CV para: DecisionTree\n",
      "‚Üí Ejecutando CV para: DecisionTree\n",
      "‚Üí Ejecutando CV para: RandomForest\n",
      "‚Üí Ejecutando CV para: RandomForest\n",
      "‚Üí Ejecutando CV para: GradientBoosting\n",
      "‚Üí Ejecutando CV para: GradientBoosting\n",
      "‚Üí Ejecutando CV para: NeuralNetwork\n",
      "‚Üí Ejecutando CV para: NeuralNetwork\n",
      "‚Üí Ejecutando CV para: Lasso Optimizado\n",
      "‚Üí Ejecutando CV para: Lasso Optimizado\n",
      "‚Üí Ejecutando CV para: Ridge Optimizado\n",
      "‚Üí Ejecutando CV para: Ridge Optimizado\n",
      "‚Üí Ejecutando CV para: RandomForest Optimizado\n",
      "‚Üí Ejecutando CV para: RandomForest Optimizado\n",
      "‚Üí Ejecutando CV para: DecisionTreeRegressor Optimizado\n",
      "‚Üí Ejecutando CV para: DecisionTreeRegressor Optimizado\n",
      "‚Üí Ejecutando CV para: NeuralNetwork Optimizado\n",
      "‚Üí Ejecutando CV para: NeuralNetwork Optimizado\n",
      "‚Üí Ejecutando CV para: GradientBoosting Optimizado\n",
      "‚Üí Ejecutando CV para: GradientBoosting Optimizado\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>R2_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoosting Optimizado</td>\n",
       "      <td>0.559039</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.312599</td>\n",
       "      <td>0.422906</td>\n",
       "      <td>0.419446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest Optimizado</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.314189</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.416497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.562411</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.424902</td>\n",
       "      <td>0.412375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.571912</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.327145</td>\n",
       "      <td>0.436553</td>\n",
       "      <td>0.392437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetwork Optimizado</td>\n",
       "      <td>0.584877</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.342144</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.364467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge Optimizado</td>\n",
       "      <td>0.587532</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.447932</td>\n",
       "      <td>0.358746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.587540</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.345248</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.358727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso Optimizado</td>\n",
       "      <td>0.588357</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.346208</td>\n",
       "      <td>0.449443</td>\n",
       "      <td>0.356948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTreeRegressor Optimizado</td>\n",
       "      <td>0.602546</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.363096</td>\n",
       "      <td>0.459290</td>\n",
       "      <td>0.325499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.617816</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.381796</td>\n",
       "      <td>0.472082</td>\n",
       "      <td>0.290335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.734001</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.538848</td>\n",
       "      <td>0.574686</td>\n",
       "      <td>-0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.795480</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.632921</td>\n",
       "      <td>0.599263</td>\n",
       "      <td>-0.175531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Modelo  rmse_mean  rmse_std  MSE_mean  MAE_mean  \\\n",
       "11       GradientBoosting Optimizado   0.559039  0.008636  0.312599  0.422906   \n",
       "8            RandomForest Optimizado   0.560440  0.009807  0.314189  0.423249   \n",
       "3                       RandomForest   0.562411  0.009469  0.316396  0.424902   \n",
       "4                   GradientBoosting   0.571912  0.007864  0.327145  0.436553   \n",
       "10          NeuralNetwork Optimizado   0.584877  0.007949  0.342144  0.446510   \n",
       "7                   Ridge Optimizado   0.587532  0.006681  0.345238  0.447932   \n",
       "1                   LinearRegression   0.587540  0.006684  0.345248  0.447910   \n",
       "6                   Lasso Optimizado   0.588357  0.006571  0.346208  0.449443   \n",
       "9   DecisionTreeRegressor Optimizado   0.602546  0.005816  0.363096  0.459290   \n",
       "5                      NeuralNetwork   0.617816  0.009945  0.381796  0.472082   \n",
       "0                              Dummy   0.734001  0.009527  0.538848  0.574686   \n",
       "2                       DecisionTree   0.795480  0.011547  0.632921  0.599263   \n",
       "\n",
       "     R2_mean  \n",
       "11  0.419446  \n",
       "8   0.416497  \n",
       "3   0.412375  \n",
       "4   0.392437  \n",
       "10  0.364467  \n",
       "7   0.358746  \n",
       "1   0.358727  \n",
       "6   0.356948  \n",
       "9   0.325499  \n",
       "5   0.290335  \n",
       "0  -0.000736  \n",
       "2  -0.175531  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí LaTeX generado: Informe/tex/tables/cv_results_all_models.tex\n"
     ]
    }
   ],
   "source": [
    "cv_results_df = cross_validate_models(\n",
    "    models_dict=all_models,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    preprocessor=preprocessor,\n",
    "    cv_folds=5,\n",
    "    export_latex=True,\n",
    "    latex_filename=\"cv_results_all_models.tex\",\n",
    "    latex_caption=\"Validaci√≥n cruzada (5-Fold) para todos los modelos optimizados.\",\n",
    "    latex_label=\"tab:cv-all-models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the test data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "1bCWQ0jJsi6v",
    "outputId": "dff0048d-920f-4ca1-963a-22a1be16389b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelos finales con 16013 muestras y generando predicciones...\n",
      "‚Üí Procesando Dummy...\n",
      "   Guardado: pred_Dummy.csv\n",
      "‚Üí Procesando LinearRegression...\n",
      "   Guardado: pred_LinearRegression.csv\n",
      "‚Üí Procesando DecisionTree...\n",
      "   Guardado: pred_LinearRegression.csv\n",
      "‚Üí Procesando DecisionTree...\n",
      "   Guardado: pred_DecisionTree.csv\n",
      "‚Üí Procesando RandomForest...\n",
      "   Guardado: pred_DecisionTree.csv\n",
      "‚Üí Procesando RandomForest...\n",
      "   Guardado: pred_RandomForest.csv\n",
      "‚Üí Procesando GradientBoosting...\n",
      "   Guardado: pred_RandomForest.csv\n",
      "‚Üí Procesando GradientBoosting...\n",
      "   Guardado: pred_GradientBoosting.csv\n",
      "‚Üí Procesando NeuralNetwork...\n",
      "   Guardado: pred_GradientBoosting.csv\n",
      "‚Üí Procesando NeuralNetwork...\n",
      "   Guardado: pred_NeuralNetwork.csv\n",
      "‚Üí Procesando Lasso Optimizado...\n",
      "   Guardado: pred_NeuralNetwork.csv\n",
      "‚Üí Procesando Lasso Optimizado...\n",
      "   Guardado: pred_Lasso Optimizado.csv\n",
      "‚Üí Procesando Ridge Optimizado...\n",
      "   Guardado: pred_Lasso Optimizado.csv\n",
      "‚Üí Procesando Ridge Optimizado...\n",
      "   Guardado: pred_Ridge Optimizado.csv\n",
      "‚Üí Procesando RandomForest Optimizado...\n",
      "   Guardado: pred_Ridge Optimizado.csv\n",
      "‚Üí Procesando RandomForest Optimizado...\n",
      "   Guardado: pred_RandomForest Optimizado.csv\n",
      "‚Üí Procesando DecisionTreeRegressor Optimizado...\n",
      "   Guardado: pred_DecisionTreeRegressor Optimizado.csv\n",
      "‚Üí Procesando NeuralNetwork Optimizado...\n",
      "   Guardado: pred_RandomForest Optimizado.csv\n",
      "‚Üí Procesando DecisionTreeRegressor Optimizado...\n",
      "   Guardado: pred_DecisionTreeRegressor Optimizado.csv\n",
      "‚Üí Procesando NeuralNetwork Optimizado...\n",
      "   Guardado: pred_NeuralNetwork Optimizado.csv\n",
      "‚Üí Procesando GradientBoosting Optimizado...\n",
      "   Guardado: pred_NeuralNetwork Optimizado.csv\n",
      "‚Üí Procesando GradientBoosting Optimizado...\n",
      "   Guardado: pred_GradientBoosting Optimizado.csv\n",
      "\n",
      "¬°Todas las predicciones han sido generadas exitosamente!\n",
      "   Guardado: pred_GradientBoosting Optimizado.csv\n",
      "\n",
      "¬°Todas las predicciones han sido generadas exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# --- Carga y Preprocesamiento de Test ---\n",
    "# Pasamos el mapa de precios calculado en train para evitar data leakage y errores\n",
    "df_pre_test, _ = preprocess_data(df_raw_test, price_map=train_price_map)\n",
    "\n",
    "# Aplicamos el mismo tratamiento de outliers (clipping) usando las columnas definidas\n",
    "# Nota: Idealmente deber√≠amos usar los l√≠mites de train, pero IQR_outlier_removal usa los del propio DF.\n",
    "# Para consistencia con el c√≥digo previo, lo mantenemos, pero aseguramos pasar las columnas.\n",
    "df_pre_test_IQR = IQR_outlier_removal(df_pre_test.copy(), [ \"price_log\", \"minimum_nights_log\", \"number_of_reviews_log\" ,\"reviews_per_month\", \"availability_365_log\", \"calculated_host_listings_count_log\" , \"days_since_last_review\"])\n",
    "\n",
    "# --- Generaci√≥n de Predicciones ---\n",
    "\n",
    "if is_Drive:\n",
    "    pred_folder = os.path.join(base_path, \"pred\")\n",
    "else:\n",
    "    pred_folder = \"pred\"\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "\n",
    "# Definir X e y completos para re-entrenamiento final\n",
    "# Usamos df_pre_IQR (train) para entrenar\n",
    "target_col = \"price_log\"\n",
    "if target_col not in df_pre_IQR.columns:\n",
    "    raise ValueError(f\"La columna objetivo '{target_col}' no est√° en el DataFrame de entrenamiento.\")\n",
    "\n",
    "X_full = df_pre_IQR.drop(columns=[target_col], errors='ignore')\n",
    "y_full = df_pre_IQR[target_col]\n",
    "\n",
    "# Alinear columnas de test con train (asegurar mismo orden y columnas)\n",
    "# Rellenar columnas faltantes con 0 si las hubiera (ej. one-hot encoding diferencias)\n",
    "for col in X_full.columns:\n",
    "    if col not in df_pre_test_IQR.columns:\n",
    "        df_pre_test_IQR[col] = 0\n",
    "        \n",
    "test_df_final = df_pre_test_IQR[X_full.columns]\n",
    "\n",
    "print(f\"Entrenando modelos finales con {X_full.shape[0]} muestras y generando predicciones...\")\n",
    "\n",
    "# Guardamos los IDs para el archivo de submission\n",
    "test_ids = df_raw_test[\"id\"]\n",
    "\n",
    "for name, model in all_models.items():\n",
    "    print(f\"‚Üí Procesando {name}...\")\n",
    "    \n",
    "    # Crear pipeline si no lo es\n",
    "    if isinstance(model, Pipeline):\n",
    "        pipe = model\n",
    "    else:\n",
    "        pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    # Re-entrenar con TODO el dataset (Train + Val)\n",
    "    pipe.fit(X_full, y_full)\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred_log = pipe.predict(test_df_final)\n",
    "    y_pred = np.expm1(y_pred_log) # Revertir log\n",
    "    \n",
    "    # Guardar\n",
    "    sub = pd.DataFrame({\"id\": test_ids, \"price\": y_pred})\n",
    "    fname = f\"pred_{name}.csv\"\n",
    "    sub.to_csv(os.path.join(pred_folder, fname), index=False)\n",
    "    print(f\"   Guardado: {fname}\")\n",
    "\n",
    "print(\"\\n¬°Todas las predicciones han sido generadas exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entorno Utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Informaci√≥n de Python ===\n",
      "Int√©rprete: /mnt/d/git/OBL MACHINE/.venv/bin/python\n",
      "Versi√≥n de Python: 3.12.3 (main, Nov  6 2025, 13:44:16) [GCC 13.3.0]\n",
      "Versi√≥n de pip: 25.3\n",
      "\n",
      "=== Librer√≠as instaladas ===\n",
      "GPUtil: 1.4.0\n",
      "Jinja2: 3.1.6\n",
      "MarkupSafe: 3.0.3\n",
      "PyYAML: 6.0.3\n",
      "Pygments: 2.19.2\n",
      "Unidecode: 1.4.0\n",
      "asttokens: 3.0.1\n",
      "autocommand: 2.2.2\n",
      "backports.tarfile: 1.2.0\n",
      "certifi: 2025.11.12\n",
      "charset-normalizer: 3.4.4\n",
      "comm: 0.2.3\n",
      "contourpy: 1.3.3\n",
      "cycler: 0.12.1\n",
      "debugpy: 1.8.17\n",
      "decorator: 5.2.1\n",
      "executing: 2.2.1\n",
      "filelock: 3.20.0\n",
      "fonttools: 4.61.0\n",
      "fsspec: 2025.12.0\n",
      "hf-xet: 1.2.0\n",
      "huggingface-hub: 0.36.0\n",
      "idna: 3.11\n",
      "importlib_metadata: 8.0.0\n",
      "inflect: 7.3.1\n",
      "ipykernel: 7.1.0\n",
      "ipython: 9.8.0\n",
      "ipython_pygments_lexers: 1.1.1\n",
      "ipywidgets: 8.1.8\n",
      "jaraco.collections: 5.1.0\n",
      "jaraco.context: 5.3.0\n",
      "jaraco.functools: 4.0.1\n",
      "jaraco.text: 3.12.1\n",
      "jedi: 0.19.2\n",
      "joblib: 1.5.2\n",
      "jupyter_client: 8.6.3\n",
      "jupyter_core: 5.9.1\n",
      "jupyterlab_widgets: 3.0.16\n",
      "kiwisolver: 1.4.9\n",
      "matplotlib: 3.10.7\n",
      "matplotlib-inline: 0.2.1\n",
      "more-itertools: 10.3.0\n",
      "mpmath: 1.3.0\n",
      "nest-asyncio: 1.6.0\n",
      "networkx: 3.6.1\n",
      "numpy: 2.3.5\n",
      "nvidia-cublas-cu12: 12.8.4.1\n",
      "nvidia-cuda-cupti-cu12: 12.8.90\n",
      "nvidia-cuda-nvrtc-cu12: 12.8.93\n",
      "nvidia-cuda-runtime-cu12: 12.8.90\n",
      "nvidia-cudnn-cu12: 9.10.2.21\n",
      "nvidia-cufft-cu12: 11.3.3.83\n",
      "nvidia-cufile-cu12: 1.13.1.3\n",
      "nvidia-curand-cu12: 10.3.9.90\n",
      "nvidia-cusolver-cu12: 11.7.3.90\n",
      "nvidia-cusparse-cu12: 12.5.8.93\n",
      "nvidia-cusparselt-cu12: 0.7.1\n",
      "nvidia-nccl-cu12: 2.27.5\n",
      "nvidia-nvjitlink-cu12: 12.8.93\n",
      "nvidia-nvshmem-cu12: 3.3.20\n",
      "nvidia-nvtx-cu12: 12.8.90\n",
      "packaging: 24.2\n",
      "pandas: 2.3.3\n",
      "parso: 0.8.5\n",
      "pexpect: 4.9.0\n",
      "pillow: 12.0.0\n",
      "pip: 25.3\n",
      "platformdirs: 4.2.2\n",
      "prompt_toolkit: 3.0.52\n",
      "psutil: 7.1.3\n",
      "ptyprocess: 0.7.0\n",
      "pure_eval: 0.2.3\n",
      "pyparsing: 3.2.5\n",
      "python-dateutil: 2.9.0.post0\n",
      "pytz: 2025.2\n",
      "pyzmq: 27.1.0\n",
      "regex: 2025.11.3\n",
      "requests: 2.32.5\n",
      "safetensors: 0.7.0\n",
      "scikit-learn: 1.7.2\n",
      "scipy: 1.16.3\n",
      "seaborn: 0.13.2\n",
      "sentence-transformers: 5.1.2\n",
      "setuptools: 80.9.0\n",
      "six: 1.17.0\n",
      "stack-data: 0.6.3\n",
      "sympy: 1.14.0\n",
      "threadpoolctl: 3.6.0\n",
      "tokenizers: 0.22.1\n",
      "tomli: 2.0.1\n",
      "torch: 2.9.1\n",
      "tornado: 6.5.2\n",
      "tqdm: 4.67.1\n",
      "traitlets: 5.14.3\n",
      "transformers: 4.57.3\n",
      "triton: 3.5.1\n",
      "typeguard: 4.3.0\n",
      "typing_extensions: 4.12.2\n",
      "tzdata: 2025.2\n",
      "urllib3: 2.6.1\n",
      "utm: 0.8.1\n",
      "wcwidth: 0.2.14\n",
      "wheel: 0.45.1\n",
      "widgetsnbextension: 4.0.15\n",
      "zipp: 3.19.2\n",
      "\n",
      "=== Informaci√≥n del sistema ===\n",
      "Sistema Operativo: Linux\n",
      "Versi√≥n OS: #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "Nombre del SO: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "Arquitectura: ('64bit', 'ELF')\n",
      "CPU: x86_64\n",
      "N√∫cleos (F√≠sicos): 4\n",
      "N√∫cleos (L√≥gicos): 8\n",
      "RAM Total: 31.27\n",
      "\n",
      "=== Informaci√≥n de GPU ===\n",
      "[{'Nombre': 'NVIDIA GeForce GTX 1650', 'Memoria': 4096.0, 'Uso': 411.0}]\n",
      "\n",
      "[INFO] Informaci√≥n exportada exitosamente a: /mnt/d/git/OBL MACHINE/Informe/code/system_info.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import psutil\n",
    "import importlib.metadata as metadata\n",
    "import GPUtil\n",
    "import os\n",
    "\n",
    "def obtener_info_python():\n",
    "    info = {\n",
    "        \"Int√©rprete\": sys.executable,\n",
    "        \"Versi√≥n de Python\": sys.version,\n",
    "        \"Versi√≥n de pip\": metadata.version(\"pip\")\n",
    "    }\n",
    "    return info\n",
    "\n",
    "def obtener_librerias_instaladas():\n",
    "    return {pkg.metadata['Name']: pkg.version for pkg in metadata.distributions()}\n",
    "\n",
    "def obtener_info_sistema():\n",
    "    info = {\n",
    "        \"Sistema Operativo\": platform.system(),\n",
    "        \"Versi√≥n OS\": platform.version(),\n",
    "        \"Nombre del SO\": platform.platform(),\n",
    "        \"Arquitectura\": platform.architecture(),\n",
    "        \"CPU\": platform.processor(),\n",
    "        \"N√∫cleos (F√≠sicos)\": psutil.cpu_count(logical=False),\n",
    "        \"N√∫cleos (L√≥gicos)\": psutil.cpu_count(logical=True),\n",
    "        \"RAM Total\": round(psutil.virtual_memory().total / (1024 ** 3), 2),  # En GB\n",
    "    }\n",
    "    return info\n",
    "\n",
    "def obtener_info_gpu():\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if gpus:\n",
    "            return [{\"Nombre\": gpu.name, \"Memoria\": gpu.memoryTotal, \"Uso\": gpu.memoryUsed} for gpu in gpus]\n",
    "        else:\n",
    "            return \"No se encontr√≥ GPU\"\n",
    "    except Exception:\n",
    "        return \"Error al obtener info de GPU\"\n",
    "\n",
    "def generar_reporte():\n",
    "    lines = []\n",
    "    lines.append(\"=== Informaci√≥n de Python ===\")\n",
    "    for clave, valor in obtener_info_python().items():\n",
    "        lines.append(f\"{clave}: {valor}\")\n",
    "        \n",
    "    lines.append(\"\\n=== Librer√≠as instaladas ===\")\n",
    "    # Ordenamos alfab√©ticamente para mayor claridad\n",
    "    libs = obtener_librerias_instaladas()\n",
    "    for nombre in sorted(libs.keys()):\n",
    "        lines.append(f\"{nombre}: {libs[nombre]}\")\n",
    "        \n",
    "    lines.append(\"\\n=== Informaci√≥n del sistema ===\")\n",
    "    for clave, valor in obtener_info_sistema().items():\n",
    "        lines.append(f\"{clave}: {valor}\")\n",
    "        \n",
    "    lines.append(\"\\n=== Informaci√≥n de GPU ===\")\n",
    "    lines.append(str(obtener_info_gpu()))\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def guardar_info_txt(filename=\"system_info.txt\"):\n",
    "    reporte = generar_reporte()\n",
    "    \n",
    "    # Imprimir en consola\n",
    "    print(reporte)\n",
    "    \n",
    "    # Guardar en archivo\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(reporte)\n",
    "    \n",
    "    print(f\"\\n[INFO] Informaci√≥n exportada exitosamente a: {os.path.abspath(filename)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    guardar_info_txt(\"Informe/code/system_info.txt\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
