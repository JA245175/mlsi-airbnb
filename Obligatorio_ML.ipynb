{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKtpYuuTY0iQ",
    "outputId": "5952494a-6e2b-49df-8346-606a98a164ff"
   },
   "outputs": [],
   "source": [
    "# Indicador para saber si se está trabajando en Google Drive\n",
    "is_Drive = False\n",
    "\n",
    "# Ruta base donde se guardarán o cargarán los archivos\n",
    "base_path = ''\n",
    "\n",
    "# Si estamos trabajando en Google Drive, ejecutar este bloque\n",
    "if (is_Drive):\n",
    "    from google.colab import drive, files # type: ignore\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    base_path = '/content/drive/MyDrive/Machine_Learning_Para_Sistemas_Inteligentes/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7279fc17"
   },
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NWK2XMijGsY3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Para gráficos estadísticos\n",
    "from jinja2 import Environment, BaseLoader # Para generación de informes\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "U-uUWi9KEHzW",
    "outputId": "b174182a-85c6-49e6-d597-0f00a44d5ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "(16013, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30814163</td>\n",
       "      <td>3 bedrooms, 2 bathrooms. Patio, terrace and BBQ!</td>\n",
       "      <td>157770305</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Constitucion</td>\n",
       "      <td>-34.62142</td>\n",
       "      <td>-58.37754</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2212</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10-11-2019</td>\n",
       "      <td>2.19</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32539509</td>\n",
       "      <td>Studio with balcony and gim @Palermo Hollywood</td>\n",
       "      <td>16133446</td>\n",
       "      <td>Luis &amp; Florencia</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>-34.57949</td>\n",
       "      <td>-58.43199</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2691</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36262352</td>\n",
       "      <td>Nice Niceto. Der Wohnung in Buenos aires</td>\n",
       "      <td>257784804</td>\n",
       "      <td>Diego</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>-34.58298</td>\n",
       "      <td>-58.44265</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1315</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>06-10-2019</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1147359</td>\n",
       "      <td>Soho Artist Studio, breakfast</td>\n",
       "      <td>4215940</td>\n",
       "      <td>Lilian</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>-34.58937</td>\n",
       "      <td>-58.43274</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2750</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>29-01-2019</td>\n",
       "      <td>0.12</td>\n",
       "      <td>6</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26470465</td>\n",
       "      <td>Perfect get-away in Buenos Aires</td>\n",
       "      <td>166597104</td>\n",
       "      <td>Mariangeles</td>\n",
       "      <td>Retiro</td>\n",
       "      <td>-34.59448</td>\n",
       "      <td>-58.37936</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1076</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10-05-2019</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              name    host_id  \\\n",
       "0  30814163  3 bedrooms, 2 bathrooms. Patio, terrace and BBQ!  157770305   \n",
       "1  32539509    Studio with balcony and gim @Palermo Hollywood   16133446   \n",
       "2  36262352          Nice Niceto. Der Wohnung in Buenos aires  257784804   \n",
       "3   1147359                     Soho Artist Studio, breakfast    4215940   \n",
       "4  26470465                  Perfect get-away in Buenos Aires  166597104   \n",
       "\n",
       "          host_name neighbourhood  latitude  longitude        room_type  \\\n",
       "0              Sara  Constitucion -34.62142  -58.37754  Entire home/apt   \n",
       "1  Luis & Florencia       Palermo -34.57949  -58.43199  Entire home/apt   \n",
       "2             Diego       Palermo -34.58298  -58.44265  Entire home/apt   \n",
       "3            Lilian       Palermo -34.58937  -58.43274  Entire home/apt   \n",
       "4       Mariangeles        Retiro -34.59448  -58.37936  Entire home/apt   \n",
       "\n",
       "   price  minimum_nights  number_of_reviews last_review  reviews_per_month  \\\n",
       "0   2212               1                 24  10-11-2019               2.19   \n",
       "1   2691               2                  0         NaN                NaN   \n",
       "2   1315               2                  8  06-10-2019               1.64   \n",
       "3   2750               1                  9  29-01-2019               0.12   \n",
       "4   1076               1                  6  10-05-2019               0.42   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               4               337  \n",
       "1                              52               179  \n",
       "2                               1                22  \n",
       "3                               6               343  \n",
       "4                               2               339  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Cargando datos...\")\n",
    "df = pd.read_csv(base_path + \"train.csv\")\n",
    "df_raw = df.copy()\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzzGsDY8EUFH",
    "outputId": "8e276899-00e8-4327-f87e-b0c080c9875b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16013 entries, 0 to 16012\n",
      "Data columns (total 15 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              16013 non-null  int64  \n",
      " 1   name                            16005 non-null  object \n",
      " 2   host_id                         16013 non-null  int64  \n",
      " 3   host_name                       16000 non-null  object \n",
      " 4   neighbourhood                   16013 non-null  object \n",
      " 5   latitude                        16013 non-null  float64\n",
      " 6   longitude                       16013 non-null  float64\n",
      " 7   room_type                       16013 non-null  object \n",
      " 8   price                           16013 non-null  int64  \n",
      " 9   minimum_nights                  16013 non-null  int64  \n",
      " 10  number_of_reviews               16013 non-null  int64  \n",
      " 11  last_review                     11463 non-null  object \n",
      " 12  reviews_per_month               11463 non-null  float64\n",
      " 13  calculated_host_listings_count  16013 non-null  int64  \n",
      " 14  availability_365                16013 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(5)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "                 id       host_id      latitude     longitude          price  \\\n",
      "count  1.601300e+04  1.601300e+04  16013.000000  16013.000000   16013.000000   \n",
      "mean   2.486345e+07  9.672329e+07    -34.592509    -58.416304    3286.097046   \n",
      "std    1.193506e+07  9.244977e+07      0.018328      0.029856   13182.202856   \n",
      "min    1.150800e+04  2.616000e+03    -34.688950    -58.530200     120.000000   \n",
      "25%    1.631890e+07  1.325351e+07    -34.603350    -58.435600    1256.000000   \n",
      "50%    2.856482e+07  6.111916e+07    -34.591870    -58.415850    2033.000000   \n",
      "75%    3.451027e+07  1.703306e+08    -34.581990    -58.392280    2990.000000   \n",
      "max    4.035243e+07  3.117862e+08    -34.534100    -58.354880  597865.000000   \n",
      "\n",
      "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
      "count    16013.000000       16013.000000       11463.000000   \n",
      "mean         5.524511          15.275027           1.257176   \n",
      "std         19.909682          30.746844           1.393336   \n",
      "min          1.000000           0.000000           0.010000   \n",
      "25%          1.000000           0.000000           0.250000   \n",
      "50%          3.000000           4.000000           0.760000   \n",
      "75%          4.000000          16.000000           1.800000   \n",
      "max       1125.000000         451.000000          15.000000   \n",
      "\n",
      "       calculated_host_listings_count  availability_365  \n",
      "count                    16013.000000      16013.000000  \n",
      "mean                         6.383813        202.430525  \n",
      "std                         14.945548        134.189981  \n",
      "min                          1.000000          0.000000  \n",
      "25%                          1.000000         83.000000  \n",
      "50%                          1.000000        180.000000  \n",
      "75%                          4.000000        344.000000  \n",
      "max                        105.000000        365.000000  \n",
      "id                                   0\n",
      "name                                 8\n",
      "host_id                              0\n",
      "host_name                           13\n",
      "neighbourhood                        0\n",
      "latitude                             0\n",
      "longitude                            0\n",
      "room_type                            0\n",
      "price                                0\n",
      "minimum_nights                       0\n",
      "number_of_reviews                    0\n",
      "last_review                       4550\n",
      "reviews_per_month                 4550\n",
      "calculated_host_listings_count       0\n",
      "availability_365                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KPYyhsHBEurc"
   },
   "outputs": [],
   "source": [
    "# --- Tratamiento de valores faltantes ---\n",
    "# imputar reviews_per_month con 0 si está vacío\n",
    "df[\"reviews_per_month\"] = df[\"reviews_per_month\"].fillna(0)\n",
    "\n",
    "# cambiamos last_review a datetime y creamos feature temporal days_since_last_review\n",
    "df[\"last_review\"] = pd.to_datetime(df[\"last_review\"], errors=\"coerce\")\n",
    "df[\"days_since_last_review\"] = (pd.Timestamp(\"today\") - df[\"last_review\"]).dt.days\n",
    "df[\"days_since_last_review\"] = df[\"days_since_last_review\"].fillna(df[\"days_since_last_review\"].max())\n",
    "\n",
    "# --- Gestión de outliers ---\n",
    "numeric_outlier_cols = [\n",
    "    \"price\",\n",
    "    \"minimum_nights\",\n",
    "    \"number_of_reviews\",\n",
    "    \"reviews_per_month\",\n",
    "    \"calculated_host_listings_count\",\n",
    "    \"availability_365\",\n",
    "    \"days_since_last_review\"\n",
    "]\n",
    "\n",
    "for col in numeric_outlier_cols:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        # Recortamos los valores extremos al rango [lower, upper]\n",
    "        df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "# --- Eliminación de columnas irrelevantes ---\n",
    "# eliminamos las columnas id name, host_name y host_id\n",
    "cols_to_drop = [\"id\", \"name\", \"host_name\", \"host_id\"]\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# --- Transformación de variables ---\n",
    "# log transform al precio para estabilizar varianza\n",
    "df[\"price\"] = np.log1p(df[\"price\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfica de los Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Variante IQR ---\n",
    "df_iqr = df.copy()\n",
    "\n",
    "df_iqr[\"price\"] =  np.expm1(df[\"price\"])  # revertimos log transform para calcular IQR\n",
    "\n",
    "# --- Variante sin tratamiento de outliers ---\n",
    "df_no_outliers = df_raw.copy()\n",
    "\n",
    "# imputar reviews_per_month con 0 si está vacío\n",
    "df_no_outliers[\"reviews_per_month\"] = df_no_outliers[\"reviews_per_month\"].fillna(0)\n",
    "\n",
    "# cambiamos last_review a datetime\n",
    "df_no_outliers[\"last_review\"] = pd.to_datetime(df_no_outliers[\"last_review\"], errors=\"coerce\")\n",
    "\n",
    "# cambiamos last_review a datetime y creamos feature temporal days_since_last_review\n",
    "df_no_outliers[\"days_since_last_review\"] = (pd.Timestamp(\"today\") - df_no_outliers[\"last_review\"]).dt.days\n",
    "df_no_outliers[\"days_since_last_review\"] = df_no_outliers[\"days_since_last_review\"].fillna(\n",
    "    df_no_outliers[\"days_since_last_review\"].max()\n",
    ")\n",
    "\n",
    "# --- Variante Winsorized ---\n",
    "df_wins = df_raw.copy()\n",
    "df_wins[\"days_since_last_review\"] = df_no_outliers[\"days_since_last_review\"]\n",
    "\n",
    "for col in numeric_outlier_cols:\n",
    "    if col in df_wins.columns:\n",
    "        lower = df_wins[col].quantile(0.01)\n",
    "        upper = df_wins[col].quantile(0.99)\n",
    "        df_wins[col] = df_wins[col].clip(lower=lower, upper=upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_format(v):\n",
    "    \"\"\"Formatea v según el patrón solicitado.\"\"\"\n",
    "\n",
    "    if pd.isna(v):\n",
    "        return \"\"\n",
    "\n",
    "    s = f\"{v:.4f}\"       # siempre 4 decimales para empezar\n",
    "    if \".\" not in s:\n",
    "        return s\n",
    "\n",
    "    entero, dec = s.split(\".\")\n",
    "\n",
    "    # Caso 0000 → sin decimales\n",
    "    if dec == \"0000\":\n",
    "        return entero\n",
    "\n",
    "    # Caso abcd → elegir según los ceros finales\n",
    "    # dec = a b c d\n",
    "    if dec.endswith(\"000\"):\n",
    "        return entero + \".\" + dec[:1]  # 1 decimal\n",
    "    if dec.endswith(\"00\"):\n",
    "        return entero + \".\" + dec[:2]  # 2 decimales\n",
    "    if dec.endswith(\"0\"):\n",
    "        return entero + \".\" + dec[:3]  # 3 decimales\n",
    "\n",
    "    # Si ninguno de los casos: todos los decimales significativos\n",
    "    return entero + \".\" + dec\n",
    "\n",
    "def latex_escape_header(s: str) -> str:\n",
    "    \"\"\"Escapa encabezados y agrega allowbreak en nombres largos.\"\"\"\n",
    "    s = str(s)\n",
    "    s = s.replace(\"_\", r\"\\_\\allowbreak \")\n",
    "    return r\"\\texttt{\" + s + \"}\"\n",
    "\n",
    "def latex_escape_row_label(s: str) -> str:\n",
    "    \"\"\"Escapa etiquetas de fila.\"\"\"\n",
    "    return str(s).replace(\"_\", r\"\\_\").replace(\"%\", r\"\\%\")\n",
    "\n",
    "def generar_tabla_descriptiva_latex(\n",
    "    df,\n",
    "    cols,\n",
    "    percentiles,\n",
    "    output_path,\n",
    "    filename,\n",
    "    caption,\n",
    "    label,\n",
    "    incluir_varianza=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera una tabla LaTeX en formato ajustado (adjustbox + booktabs)\n",
    "    basada en describe() + varianza.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # --- describe ---\n",
    "    desc = df[cols].describe(percentiles=percentiles)\n",
    "\n",
    "    # --- varianza ---\n",
    "    if incluir_varianza:\n",
    "        variance = df[cols].var()\n",
    "        variance.name = \"variance\"\n",
    "        desc = pd.concat([desc, variance.to_frame().T])\n",
    "\n",
    "    # --- columnas ---\n",
    "    cols_escaped = [latex_escape_header(c) for c in desc.columns]\n",
    "\n",
    "    # --- filas ---\n",
    "    rows = []\n",
    "    for idx in desc.index:\n",
    "        row_label = latex_escape_row_label(idx)\n",
    "        values = []\n",
    "        for c in desc.columns:\n",
    "            v = desc.loc[idx, c]\n",
    "            if pd.isna(v):\n",
    "                values.append(\"\")\n",
    "            else:\n",
    "                values.append(smart_format(v))\n",
    "        rows.append((row_label, values))\n",
    "\n",
    "    # --- template Jinja2 CORREGIDO ---\n",
    "    template_str = r\"\"\"\n",
    "\\begin{table}[H]\n",
    "    \\centering\n",
    "    \\setlength{\\tabcolsep}{3pt}\n",
    "    \\begin{scriptsize}\n",
    "    \\begin{adjustbox}{width=\\textwidth}\n",
    "    \\begin{tabular}{l{% for _ in cols %}r{% endfor %}}\n",
    "        \\toprule\n",
    "        & {% for col in cols %}{{ col }}{% if not loop.last %} & {% endif %}{% endfor %} \\\\\n",
    "        \\midrule\n",
    "        {% for row_label, values in rows -%}\n",
    "        {{ row_label }} & {% for val in values %}{{ val }}{% if not loop.last %} & {% endif %}{% endfor %} \\\\\n",
    "        {% endfor %}\n",
    "        \\bottomrule\n",
    "    \\end{tabular}\n",
    "    \\end{adjustbox}\n",
    "    \\end{scriptsize}\n",
    "    \\caption{ {{ caption }} }\n",
    "    \\label{ {{ label }} }\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "    env = Environment(loader=BaseLoader(), autoescape=False)\n",
    "    template = env.from_string(template_str)\n",
    "\n",
    "    latex_table = template.render(\n",
    "        cols=cols_escaped,\n",
    "        rows=rows,\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "    latex_table = re.sub(r'\\\\label\\{\\s*(.*?)\\s*\\}', r'\\\\label{\\1}', latex_table)\n",
    "\n",
    "    filepath = os.path.join(output_path, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(latex_table)\n",
    "\n",
    "    print(\"Archivo LaTeX generado:\", filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/df_no_outliers_desc.tex\n",
      "Archivo LaTeX generado: Informe/tex/tables/df_iqr_desc.tex\n",
      "Archivo LaTeX generado: Informe/tex/tables/df_iqr_desc_no_log.tex\n"
     ]
    }
   ],
   "source": [
    "generar_tabla_descriptiva_latex(\n",
    "    df=df_no_outliers,\n",
    "    cols=numeric_outlier_cols,\n",
    "    percentiles=[0, 0.15, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99],\n",
    "    output_path=\"Informe/tex/tables\",\n",
    "    filename=\"df_no_outliers_desc.tex\",\n",
    "    caption=r\"Estadísticos descriptivos de las variables numéricas (df\\_no\\_outliers).\",\n",
    "    label=r\"tab:df-no-outliers-desc\"\n",
    ")\n",
    "\n",
    "generar_tabla_descriptiva_latex(\n",
    "    df=df,\n",
    "    cols=numeric_outlier_cols,\n",
    "    percentiles=[0, 0.15, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99],\n",
    "    output_path=\"Informe/tex/tables\",\n",
    "    filename=\"df_iqr_desc.tex\",\n",
    "    caption=r\"Estadísticos descriptivos de las variables numéricas tras el tratamiento de outliers con IQR (además de aplicar \\lstinline[style=python]{np.expm1} a \\texttt{price}).\",\n",
    "    label=r\"tab:df-iqr-desc-log\"\n",
    ")\n",
    "\n",
    "generar_tabla_descriptiva_latex(\n",
    "    df=df_iqr,\n",
    "    cols=numeric_outlier_cols,\n",
    "    percentiles=[0, 0.15, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99],\n",
    "    output_path=\"Informe/tex/tables\",\n",
    "    filename=\"df_iqr_desc_no_log.tex\",\n",
    "    caption=r\"Estadísticos descriptivos de las variables numéricas tras el tratamiento de outliers con IQR sin aplicar transformaciones adicionales.\",\n",
    "    label=r\"tab:df-iqr-desc-no-log\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: Informe/img/histograma/price_histograma_bins50.png\n",
      "Guardado: Informe/img/histograma/minimum_nights_histograma_bins50.png\n",
      "Guardado: Informe/img/histograma/number_of_reviews_histograma_bins50.png\n",
      "Guardado: Informe/img/histograma/reviews_per_month_histograma_bins50.png\n",
      "Guardado: Informe/img/histograma/calculated_host_listings_count_histograma_bins50.png\n",
      "Guardado: Informe/img/histograma/availability_365_histograma_bins50.png\n",
      "Guardado: Informe/img/histograma/days_since_last_review_histograma_bins50.png\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta si no existe\n",
    "output_dir = \"Informe/img/histograma\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for col in numeric_outlier_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df_no_outliers[col], bins=50, kde=True)\n",
    "    plt.title(f\"Histograma de {col}\")\n",
    "\n",
    "    # ruta del archivo\n",
    "    filename = f\"{col}_histograma_bins50.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # guardar figura\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()   # cerrar figura para evitar acumulación\n",
    "\n",
    "    print(f\"Guardado: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percentiles_all_methods(\n",
    "    numeric_cols,\n",
    "    dfs,\n",
    "    labels,\n",
    "    percentiles=None,\n",
    "    output_dir=\"Informe/img/percentiles\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera y guarda gráficos de percentiles para cada columna y cada método.\n",
    "    El archivo se guarda como:\n",
    "    img/percentiles/{col}_percentiles_max=YYY_min=XXX.png\n",
    "    donde YYY y XXX son los percentiles máximo y mínimo evaluados.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if percentiles is None:\n",
    "        percentiles = [90, 95, 97, 98, 99, 99.5, 99.9]\n",
    "\n",
    "    q = [p / 100.0 for p in percentiles]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "\n",
    "        if not any(col in df.columns for df in dfs):\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        for df_tmp, label in zip(dfs, labels):\n",
    "\n",
    "            if col not in df_tmp.columns:\n",
    "                continue\n",
    "\n",
    "            series = df_tmp[col].dropna()\n",
    "            if series.empty:\n",
    "                continue\n",
    "\n",
    "            p_vals = series.quantile(q)\n",
    "            plt.plot(percentiles, p_vals.values, marker=\"o\", label=label)\n",
    "\n",
    "        # Etiquetas\n",
    "        plt.xlabel(\"Percentil\")\n",
    "        plt.ylabel(col)\n",
    "        plt.title(f\"Comparación de métodos en percentiles de {col}\")\n",
    "        plt.xticks(percentiles, [f\"{p}%\" for p in percentiles])\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Crear filename con el percentil máximo y mínimo (no los valores)\n",
    "        max_p = max(percentiles)\n",
    "        min_p = min(percentiles)\n",
    "\n",
    "        filename = f\"{col}_percentiles_max={max_p}_min={min_p}.png\"\n",
    "        # Si quisieras formato flotante fijo:\n",
    "        # filename = f\"{col}_percentiles_max={max_p:.1f}_min={min_p:.1f}.png\"\n",
    "\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Guardado: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: Informe/img/percentiles/price_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/availability_365_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=99_min=0.png\n",
      "Guardado: Informe/img/percentiles/price_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/availability_365_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=100_min=95.png\n",
      "Guardado: Informe/img/percentiles/price_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/minimum_nights_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/number_of_reviews_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/reviews_per_month_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/calculated_host_listings_count_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/availability_365_percentiles_max=12_min=0.png\n",
      "Guardado: Informe/img/percentiles/days_since_last_review_percentiles_max=12_min=0.png\n"
     ]
    }
   ],
   "source": [
    "dfs = [df_no_outliers, df_wins, df_iqr]\n",
    "labels = [\"Original (sin tratamiento de outliers)\", \"Winsorize (1–99%)\", \"IQR\"]\n",
    "\n",
    "percentiles = [0,10, 25, 50, 75, 90, 95, 99]\n",
    "plot_percentiles_all_methods(numeric_outlier_cols, dfs, labels, percentiles=percentiles)\n",
    "\n",
    "plot_percentiles_all_methods(numeric_outlier_cols, dfs, labels, percentiles=[95, 96, 97, 98, 99, 99.5, 100])\n",
    "\n",
    "plot_percentiles_all_methods(numeric_outlier_cols, dfs, labels, percentiles=[0, 0.5 , 1, 2, 3, 4, 5, 10 ,12])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6402d288"
   },
   "source": [
    "## Split the data\n",
    "\n",
    "Split the DataFrame into training and validation sets (70% for training, 30% for validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRWIQ-MZGFss",
    "outputId": "08e8796b-89ab-41ef-a101-891b673818e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños: (11209, 11) (4804, 11)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Tamaños:\", X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52b7685b"
   },
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eebdd7e2"
   },
   "outputs": [],
   "source": [
    "# Identificamos variables numéricas y categóricas\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Definimos transformaciones\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aaf85bd1"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Dummy\": DummyRegressor(strategy=\"mean\"),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"NeuralNetwork\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7760de4e"
   },
   "source": [
    "## Train the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportador a LaTeX de los modelos\n",
    "\n",
    "def export_df_to_latex(\n",
    "    df,\n",
    "    filename,\n",
    "    caption,\n",
    "    label,\n",
    "    output_dir=\"Informe/tex/tables\",\n",
    "    float_format=\"%.4f\",\n",
    "    bigTable=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Exporta un DataFrame a una tabla LaTeX con formato ajustado (adjustbox + booktabs).\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a exportar.\n",
    "    filename : str\n",
    "        Nombre del archivo .tex a generar.\n",
    "    caption : str\n",
    "        Texto del caption LaTeX.\n",
    "    label : str\n",
    "        Label LaTeX para referencias cruzadas.\n",
    "    output_dir : str\n",
    "        Carpeta de salida donde se guardará el archivo .tex.\n",
    "    float_format : str\n",
    "        Formato para los valores numéricos.\n",
    "    scriptsize : bool\n",
    "        Si True, envuelve la tabla en un entorno scriptsize.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    latex_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Convertir DataFrame a LaTeX (estructura interna)\n",
    "    # escape=True asegura que caracteres como _ se conviertan en \\\\_\n",
    "    latex_table = df.to_latex(\n",
    "        index=False,\n",
    "        float_format=float_format,\n",
    "        caption=None,\n",
    "        label=None,\n",
    "        longtable=False,\n",
    "        escape=True,\n",
    "    )\n",
    "\n",
    "    if not bigTable:\n",
    "       latex_wrapped = rf\"\"\"\n",
    "\\begin{{table}}[H]\n",
    "\\centering\n",
    "{latex_table}\n",
    "\\caption{{{caption}}}\n",
    "\\label{{{label}}}\n",
    "\\end{{table}}\n",
    "\"\"\"\n",
    "    else: \n",
    "        # Envolver en entorno table + adjustbox\n",
    "        start_scriptsize = \"    \\\\begin{scriptsize}\\n\"\n",
    "        end_scriptsize = \"    \\\\end{scriptsize}\\n\"\n",
    "\n",
    "        latex_wrapped = rf\"\"\"\n",
    "\\begin{{table}}[H]\n",
    "    \\centering\n",
    "    \\setlength{{\\tabcolsep}}{{4pt}}\n",
    "    {start_scriptsize}\\begin{{adjustbox}}{{width=\\textwidth}}\n",
    "    {latex_table}\n",
    "    \\end{{adjustbox}}\n",
    "{end_scriptsize}    \\caption{{{caption}}}\n",
    "    \\label{{{label}}}\n",
    "\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "    # Guardar archivo\n",
    "    with open(latex_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(latex_wrapped)\n",
    "\n",
    "    print(f\"Archivo LaTeX generado: {latex_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "803a1661",
    "outputId": "74ac041c-6ed0-4e56-a07d-2832ca4851e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy -> rmse: 0.683, MSE: 0.467, MAE: 0.545, R2: -0.000\n",
      "LinearRegression -> rmse: 0.544, MSE: 0.296, MAE: 0.420, R2: 0.366\n",
      "DecisionTree -> rmse: 0.730, MSE: 0.533, MAE: 0.548, R2: -0.142\n",
      "RandomForest -> rmse: 0.517, MSE: 0.268, MAE: 0.397, R2: 0.427\n",
      "GradientBoosting -> rmse: 0.521, MSE: 0.271, MAE: 0.407, R2: 0.419\n",
      "NeuralNetwork -> rmse: 0.539, MSE: 0.291, MAE: 0.420, R2: 0.378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>rmse</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.683368</td>\n",
       "      <td>0.466991</td>\n",
       "      <td>0.545486</td>\n",
       "      <td>-0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.544090</td>\n",
       "      <td>0.296034</td>\n",
       "      <td>0.420459</td>\n",
       "      <td>0.366032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.730309</td>\n",
       "      <td>0.533352</td>\n",
       "      <td>0.548152</td>\n",
       "      <td>-0.142194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.517476</td>\n",
       "      <td>0.267781</td>\n",
       "      <td>0.397447</td>\n",
       "      <td>0.426536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>0.271466</td>\n",
       "      <td>0.407025</td>\n",
       "      <td>0.418644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.290528</td>\n",
       "      <td>0.420262</td>\n",
       "      <td>0.377823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo      rmse       MSE       MAE        R2\n",
       "0             Dummy  0.683368  0.466991  0.545486 -0.000081\n",
       "1  LinearRegression  0.544090  0.296034  0.420459  0.366032\n",
       "2      DecisionTree  0.730309  0.533352  0.548152 -0.142194\n",
       "3      RandomForest  0.517476  0.267781  0.397447  0.426536\n",
       "4  GradientBoosting  0.521024  0.271466  0.407025  0.418644\n",
       "5     NeuralNetwork  0.539006  0.290528  0.420262  0.377823"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/model_results_final.tex\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"model\", model)])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_val)\n",
    "\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    results.append({\"Modelo\": name, \"rmse\": rmse, \"MSE\": mse, \"MAE\": mae, \"R2\": r2})\n",
    "    print(f\"{name} -> rmse: {rmse:.3f}, MSE: {mse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "export_df_to_latex(\n",
    "    results_df,\n",
    "    output_dir=\"Informe/tex/tables\",\n",
    "    filename=\"model_results_final.tex\",\n",
    "    caption=\"Resultados del primer barrido de modelos sobre la partición de validación (70/30).\",\n",
    "    label=\"tab:model-results-first-barrido\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8ef3cc"
   },
   "source": [
    "## Evaluate the models\n",
    "\n",
    "Evaluate the performance of models on the validation data using appropriate metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "rVbv6LxBSz8z",
    "outputId": "bad9ca68-b079-4e0e-b123-d204889d8d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha encontrado: {'model__alpha': 0.001}\n",
      "Mejor rmse (CV): 0.5424295138653626\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.542430</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.294230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.559584</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.313134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.634464</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.402544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.682922</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.466383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.682922</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.466383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.682922</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.466383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__alpha  rmse_mean  rmse_std  MSE_mean\n",
       "0               0.001   0.542430  0.010499  0.294230\n",
       "1               0.010   0.559584  0.011475  0.313134\n",
       "2               0.100   0.634464  0.008338  0.402544\n",
       "3               1.000   0.682922  0.007407  0.466383\n",
       "4              10.000   0.682922  0.007407  0.466383\n",
       "5             100.000   0.682922  0.007407  0.466383"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (mejor modelo) -> rmse: 0.543, MSE: 0.295, MAE: 0.421, R2: 0.369\n"
     ]
    }
   ],
   "source": [
    "#Regresión Lasso\n",
    "lasso_pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Lasso(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# Definimos los valores de alpha a probar (regularización)\n",
    "param_grid_lasso = {\n",
    "    \"model__alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "# Buscamos la mejor combinación\n",
    "grid_lasso = GridSearchCV(\n",
    "    estimator=lasso_pipe,\n",
    "    param_grid=param_grid_lasso,\n",
    "    scoring=\"neg_root_mean_squared_error\",  # usamos rmse\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejor alpha encontrado:\", grid_lasso.best_params_)\n",
    "print(\"Mejor rmse (CV):\", -grid_lasso.best_score_)\n",
    "\n",
    "# Tabla de resultados de GridSearch para Lasso\n",
    "lasso_cv = pd.DataFrame(grid_lasso.cv_results_)\n",
    "\n",
    "lasso_cv[\"rmse_mean\"] = -lasso_cv[\"mean_test_score\"]\n",
    "lasso_cv[\"rmse_std\"] = lasso_cv[\"std_test_score\"]\n",
    "lasso_cv[\"MSE_mean\"] = lasso_cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "lasso_summary = lasso_cv[[\n",
    "    \"param_model__alpha\",\n",
    "    \"rmse_mean\",\n",
    "    \"rmse_std\",\n",
    "    \"MSE_mean\"\n",
    "]].sort_values(by=\"rmse_mean\")\n",
    "\n",
    "display(lasso_summary)\n",
    "\n",
    "# Métricas con los mejores hiperparámetros\n",
    "best_lasso = grid_lasso.best_estimator_\n",
    "y_pred_lasso = best_lasso.predict(X_val)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_val, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "mae_lasso = mean_absolute_error(y_val, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_val, y_pred_lasso)\n",
    "\n",
    "print(f\"Lasso (mejor modelo) -> rmse: {rmse_lasso:.3f}, MSE: {mse_lasso:.3f}, \"\n",
    "      f\"MAE: {mae_lasso:.3f}, R2: {r2_lasso:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/Lasso_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "# ===== Tabla 1: Resultados de GridSearch =====\n",
    "export_df_to_latex(\n",
    "    df=lasso_summary,\n",
    "    filename=\"Lasso_gridsearch_results.tex\",\n",
    "    caption=\"Resultados del GridSearchCV para la regresión Lasso.\",\n",
    "    label=\"tab:lasso-gridsearch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "J_zFirR3S_1Q",
    "outputId": "3f8aeb68-518b-4ce9-dde6-476633af8b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha: {'model__alpha': 0.001}\n",
      "Mejor rmse: 0.5408449660432584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.540845</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>0.292513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.540846</td>\n",
       "      <td>0.011319</td>\n",
       "      <td>0.292514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.540852</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.292521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.540987</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.292667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.541496</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.293218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.544347</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.296314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__alpha  rmse_mean  rmse_std  MSE_mean\n",
       "0               0.001   0.540845  0.011323  0.292513\n",
       "1               0.010   0.540846  0.011319  0.292514\n",
       "2               0.100   0.540852  0.011297  0.292521\n",
       "3               1.000   0.540987  0.011174  0.292667\n",
       "4              10.000   0.541496  0.010927  0.293218\n",
       "5             100.000   0.544347  0.010918  0.296314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (mejor modelo) -> rmse: 0.544, MSE: 0.296, MAE: 0.420, R2: 0.366\n"
     ]
    }
   ],
   "source": [
    "#Regularización (Ridge)\n",
    "ridge_pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Ridge(max_iter=10000, random_state=42))\n",
    "  ])\n",
    "\n",
    "param_grid_ridge = {\n",
    "    \"model__alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "grid_ridge = GridSearchCV(\n",
    "    estimator=ridge_pipe,\n",
    "    param_grid=param_grid_ridge,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor alpha:\", grid_ridge.best_params_)\n",
    "print(\"Mejor rmse:\", -grid_ridge.best_score_)\n",
    "\n",
    "ridge_cv = pd.DataFrame(grid_ridge.cv_results_)\n",
    "ridge_cv[\"rmse_mean\"] = -ridge_cv[\"mean_test_score\"]\n",
    "ridge_cv[\"rmse_std\"] = ridge_cv[\"std_test_score\"]\n",
    "ridge_cv[\"MSE_mean\"] = ridge_cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "ridge_summary = ridge_cv[[\n",
    "    \"param_model__alpha\",\n",
    "    \"rmse_mean\",\n",
    "    \"rmse_std\",\n",
    "    \"MSE_mean\"\n",
    "]].sort_values(by=\"rmse_mean\")\n",
    "\n",
    "display(ridge_summary)\n",
    "\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "y_pred_ridge = best_ridge.predict(X_val)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_val, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "mae_ridge = mean_absolute_error(y_val, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_val, y_pred_ridge)\n",
    "\n",
    "print(f\"Ridge (mejor modelo) -> rmse: {rmse_ridge:.3f}, MSE: {mse_ridge:.3f}, \"\n",
    "      f\"MAE: {mae_ridge:.3f}, R2: {r2_ridge:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/Ridge_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "export_df_to_latex(\n",
    "    df=ridge_summary,\n",
    "    filename=\"Ridge_gridsearch_results.tex\",\n",
    "    caption=\"Resultados del GridSearchCV para regresión Ridge.\",\n",
    "    label=\"tab:ridge-gridsearch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "OzmbwBaZse7o",
    "outputId": "a552ffe2-2681-4034-8fa0-c154d1ea73f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DecisionTree - mejor params: {'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2}, rmse: 0.552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.551545</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.304202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.551545</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.304202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.551610</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.551610</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.551624</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.304289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.551739</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.304416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551871</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>0.304562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551871</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>0.304562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552166</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.304888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564703</td>\n",
       "      <td>0.012516</td>\n",
       "      <td>0.318889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__max_depth  param_model__min_samples_split  \\\n",
       "34                      5                               5   \n",
       "33                      5                               2   \n",
       "30                      5                               2   \n",
       "31                      5                               5   \n",
       "32                      5                              10   \n",
       "35                      5                              10   \n",
       "27                      5                               2   \n",
       "28                      5                               5   \n",
       "29                      5                              10   \n",
       "44                     10                              10   \n",
       "\n",
       "    param_model__min_samples_leaf  rmse_mean  rmse_std  MSE_mean  \n",
       "34                              4   0.551545  0.012454  0.304202  \n",
       "33                              4   0.551545  0.012454  0.304202  \n",
       "30                              2   0.551610  0.012457  0.304274  \n",
       "31                              2   0.551610  0.012457  0.304274  \n",
       "32                              2   0.551624  0.012244  0.304289  \n",
       "35                              4   0.551739  0.012281  0.304416  \n",
       "27                              1   0.551871  0.012227  0.304562  \n",
       "28                              1   0.551871  0.012227  0.304562  \n",
       "29                              1   0.552166  0.011864  0.304888  \n",
       "44                              4   0.564703  0.012516  0.318889  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree (mejor modelo en validación) -> rmse: 0.545, MSE: 0.297, MAE: 0.426, R2: 0.363\n"
     ]
    }
   ],
   "source": [
    "optimized_models = {}\n",
    "\n",
    "# --- Decision Tree ---\n",
    "dt_pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_dt = {\n",
    "    \"model__max_depth\": [1, 2, 3, 5, 10, 20, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt_pipe,\n",
    "    param_grid=param_grid_dt,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "optimized_models[\"DecisionTree\"] = grid_dt.best_estimator_\n",
    "print(f\"✅ DecisionTree - mejor params: {grid_dt.best_params_}, rmse: {-grid_dt.best_score_:.3f}\")\n",
    "\n",
    "dt_cv = pd.DataFrame(grid_dt.cv_results_)\n",
    "dt_cv[\"rmse_mean\"] = -dt_cv[\"mean_test_score\"]\n",
    "dt_cv[\"rmse_std\"] = dt_cv[\"std_test_score\"]\n",
    "dt_cv[\"MSE_mean\"] = dt_cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "dt_summary = dt_cv[[\n",
    "    \"param_model__max_depth\",\n",
    "    \"param_model__min_samples_split\",\n",
    "    \"param_model__min_samples_leaf\",\n",
    "    \"rmse_mean\",\n",
    "    \"rmse_std\",\n",
    "    \"MSE_mean\"\n",
    "]].sort_values(by=\"rmse_mean\")\n",
    "\n",
    "display(dt_summary.head(10))  # por ejemplo, los 10 mejores\n",
    "\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_val)\n",
    "\n",
    "mse_dt = mean_squared_error(y_val, y_pred_dt)\n",
    "rmse_dt = np.sqrt(mse_dt)\n",
    "mae_dt = mean_absolute_error(y_val, y_pred_dt)\n",
    "r2_dt = r2_score(y_val, y_pred_dt)\n",
    "\n",
    "print(\n",
    "    f\"DecisionTree (mejor modelo en validación) -> \"\n",
    "    f\"rmse: {rmse_dt:.3f}, MSE: {mse_dt:.3f}, MAE: {mae_dt:.3f}, R2: {r2_dt:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/DecisionTreeRegressor_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "export_df_to_latex(\n",
    "    df = dt_summary,   # solo los 10 mejores, o usa dt_summary completo\n",
    "    filename = \"DecisionTreeRegressor_gridsearch_results.tex\",\n",
    "    caption = \"Resultados del GridSearchCV para el modelo Decision Tree Regressor.\",\n",
    "    label = \"tab:decisiontreeregressor-gridsearch\",\n",
    "    bigTable = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "U8xXgHNvsiFV",
    "outputId": "37899a34-4b69-42ef-f4e3-5c477316e72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RandomForest - mejor params: {'model__max_depth': 10, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, rmse: 0.524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524255</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.274843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524268</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.274857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524281</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>0.274871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524292</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524481</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.275081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524535</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.275137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524540</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.275142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524571</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.275174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525130</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.275761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525177</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.275811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_model__n_estimators param_model__max_depth  \\\n",
       "63                        200                     10   \n",
       "59                        200                     10   \n",
       "51                        200                     10   \n",
       "55                        200                     10   \n",
       "50                        100                     10   \n",
       "54                        100                     10   \n",
       "58                        100                     10   \n",
       "62                        100                     10   \n",
       "61                         50                     10   \n",
       "57                         50                     10   \n",
       "\n",
       "    param_model__min_samples_split  param_model__min_samples_leaf  rmse_mean  \\\n",
       "63                               5                              2   0.524255   \n",
       "59                               2                              2   0.524268   \n",
       "51                               2                              1   0.524281   \n",
       "55                               5                              1   0.524292   \n",
       "50                               2                              1   0.524481   \n",
       "54                               5                              1   0.524535   \n",
       "58                               2                              2   0.524540   \n",
       "62                               5                              2   0.524571   \n",
       "61                               5                              2   0.525130   \n",
       "57                               2                              2   0.525177   \n",
       "\n",
       "    rmse_std  MSE_mean  \n",
       "63  0.011130  0.274843  \n",
       "59  0.011111  0.274857  \n",
       "51  0.011328  0.274871  \n",
       "55  0.011292  0.274882  \n",
       "50  0.011583  0.275081  \n",
       "54  0.011561  0.275137  \n",
       "58  0.011248  0.275142  \n",
       "62  0.011224  0.275174  \n",
       "61  0.011191  0.275761  \n",
       "57  0.011091  0.275811  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (mejor modelo en validación) -> rmse: 0.513, MSE: 0.263, MAE: 0.398, R2: 0.437\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest ---\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"model__n_estimators\": [1, 50, 100, 200],\n",
    "    \"model__max_depth\": [1, 3, 5, 10, 20, None],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf_pipe,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "optimized_models[\"RandomForest\"] = grid_rf.best_estimator_\n",
    "print(f\"✅ RandomForest - mejor params: {grid_rf.best_params_}, rmse: {-grid_rf.best_score_:.3f}\")\n",
    "\n",
    "rf_cv = pd.DataFrame(grid_rf.cv_results_)\n",
    "rf_cv[\"rmse_mean\"] = -rf_cv[\"mean_test_score\"]\n",
    "rf_cv[\"rmse_std\"] = rf_cv[\"std_test_score\"]\n",
    "rf_cv[\"MSE_mean\"] = rf_cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "rf_summary = rf_cv[[\n",
    "    \"param_model__n_estimators\",\n",
    "    \"param_model__max_depth\",\n",
    "    \"param_model__min_samples_split\",\n",
    "    \"param_model__min_samples_leaf\",\n",
    "    \"rmse_mean\",\n",
    "    \"rmse_std\",\n",
    "    \"MSE_mean\"\n",
    "]].sort_values(by=\"rmse_mean\")\n",
    "\n",
    "display(rf_summary.head(10))\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_val)\n",
    "\n",
    "mse_rf = mean_squared_error(y_val, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "mae_rf = mean_absolute_error(y_val, y_pred_rf)\n",
    "r2_rf = r2_score(y_val, y_pred_rf)\n",
    "\n",
    "print(\n",
    "    f\"RandomForest (mejor modelo en validación) -> \"\n",
    "    f\"rmse: {rmse_rf:.3f}, MSE: {mse_rf:.3f}, MAE: {mae_rf:.3f}, R2: {r2_rf:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/RandomForestRegressor_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "export_df_to_latex(\n",
    "    df = rf_summary, \n",
    "    filename = \"RandomForestRegressor_gridsearch_results.tex\",\n",
    "    caption = \"Resultados del GridSearchCV para el modelo Random Forest Regressor.\",\n",
    "    label = \"tab:randomforestregressor-gridsearch\",\n",
    "    bigTable = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "1bCWQ0jJsi6v",
    "outputId": "dff0048d-920f-4ca1-963a-22a1be16389b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradientBoosting - mejor params: {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_split': 5, 'model__n_estimators': 200}, rmse: 0.521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.521062</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.271506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521295</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.271749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521509</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.271972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522077</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.272565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522271</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.272767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522347</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.272846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.522548</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.273056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522761</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.273279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522821</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.273341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>100</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522856</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.273378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_model__n_estimators  param_model__learning_rate  \\\n",
       "23                        200                        0.05   \n",
       "20                        200                        0.05   \n",
       "49                        100                        0.10   \n",
       "28                        100                        0.05   \n",
       "52                        100                        0.10   \n",
       "50                        200                        0.10   \n",
       "25                        100                        0.05   \n",
       "29                        200                        0.05   \n",
       "53                        200                        0.10   \n",
       "76                        100                        0.20   \n",
       "\n",
       "    param_model__max_depth  param_model__min_samples_split  rmse_mean  \\\n",
       "23                       5                               5   0.521062   \n",
       "20                       5                               2   0.521295   \n",
       "49                       5                               2   0.521509   \n",
       "28                       7                               5   0.522077   \n",
       "52                       5                               5   0.522271   \n",
       "50                       5                               2   0.522347   \n",
       "25                       7                               2   0.522548   \n",
       "29                       7                               5   0.522761   \n",
       "53                       5                               5   0.522821   \n",
       "76                       3                               5   0.522856   \n",
       "\n",
       "    rmse_std  MSE_mean  \n",
       "23  0.009689  0.271506  \n",
       "20  0.010001  0.271749  \n",
       "49  0.009175  0.271972  \n",
       "28  0.009619  0.272565  \n",
       "52  0.008837  0.272767  \n",
       "50  0.008686  0.272846  \n",
       "25  0.009772  0.273056  \n",
       "29  0.009757  0.273279  \n",
       "53  0.009115  0.273341  \n",
       "76  0.009973  0.273378  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting (mejor modelo en validación) -> rmse: 0.513, MSE: 0.263, MAE: 0.400, R2: 0.436\n"
     ]
    }
   ],
   "source": [
    "# --- Gradient Boosting ---\n",
    "gb_pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_gb = {\n",
    "    \"model__n_estimators\": [50, 100, 200],\n",
    "    \"model__learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"model__max_depth\": [1, 2, 3, 5, 7],\n",
    "    \"model__min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(\n",
    "    estimator=gb_pipe,\n",
    "    param_grid=param_grid_gb,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gb.fit(X_train, y_train)\n",
    "optimized_models[\"GradientBoosting\"] = grid_gb.best_estimator_\n",
    "print(f\"✅ GradientBoosting - mejor params: {grid_gb.best_params_}, rmse: {-grid_gb.best_score_:.3f}\")\n",
    "\n",
    "gb_cv = pd.DataFrame(grid_gb.cv_results_)\n",
    "gb_cv[\"rmse_mean\"] = -gb_cv[\"mean_test_score\"]\n",
    "gb_cv[\"rmse_std\"] = gb_cv[\"std_test_score\"]\n",
    "gb_cv[\"MSE_mean\"] = gb_cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "gb_summary = gb_cv[[\n",
    "    \"param_model__n_estimators\",\n",
    "    \"param_model__learning_rate\",\n",
    "    \"param_model__max_depth\",\n",
    "    \"param_model__min_samples_split\",\n",
    "    \"rmse_mean\",\n",
    "    \"rmse_std\",\n",
    "    \"MSE_mean\"\n",
    "]].sort_values(by=\"rmse_mean\")\n",
    "\n",
    "display(gb_summary.head(10))\n",
    "\n",
    "best_gb = grid_gb.best_estimator_\n",
    "y_pred_gb = best_gb.predict(X_val)\n",
    "\n",
    "mse_gb = mean_squared_error(y_val, y_pred_gb)\n",
    "rmse_gb = np.sqrt(mse_gb)\n",
    "mae_gb = mean_absolute_error(y_val, y_pred_gb)\n",
    "r2_gb = r2_score(y_val, y_pred_gb)\n",
    "\n",
    "print(\n",
    "    f\"GradientBoosting (mejor modelo en validación) -> \"\n",
    "    f\"rmse: {rmse_gb:.3f}, MSE: {mse_gb:.3f}, MAE: {mae_gb:.3f}, R2: {r2_gb:.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/GradientBoostingRegressor_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "export_df_to_latex(\n",
    "    df = rf_summary,   # solo los 10 mejores, o usa rf_summary completo\n",
    "    filename = \"GradientBoostingRegressor_gridsearch_results.tex\",\n",
    "    caption = \"Resultados del GridSearchCV para el modelo Gradient Boosting.\",\n",
    "    label = \"tab:GradientBoostingRegressor-gridsearch\",\n",
    "    bigTable = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "DjRqefNfsb9S",
    "outputId": "bebfbcd2-da5d-44f6-f96c-ef4441e8d332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NeuralNetwork - mejor params: {'model__alpha': 0.01, 'model__hidden_layer_sizes': (64,), 'model__learning_rate_init': 0.001}, rmse: 0.541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__hidden_layer_sizes</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__learning_rate_init</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.541132</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.292824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.541264</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.292967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.541546</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.293272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.543828</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.295749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.544007</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.295944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.544008</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>0.295945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.544228</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.296184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.544758</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.296762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.544838</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.296848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.545197</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.297240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__hidden_layer_sizes  param_model__alpha  \\\n",
       "12                           (64,)              0.0100   \n",
       "0                            (64,)              0.0001   \n",
       "6                            (64,)              0.0010   \n",
       "13                           (64,)              0.0100   \n",
       "4                         (64, 32)              0.0001   \n",
       "10                        (64, 32)              0.0010   \n",
       "16                        (64, 32)              0.0100   \n",
       "8                        (128, 64)              0.0010   \n",
       "2                        (128, 64)              0.0001   \n",
       "7                            (64,)              0.0010   \n",
       "\n",
       "    param_model__learning_rate_init  rmse_mean  rmse_std  MSE_mean  \n",
       "12                            0.001   0.541132  0.008048  0.292824  \n",
       "0                             0.001   0.541264  0.007601  0.292967  \n",
       "6                             0.001   0.541546  0.007332  0.293272  \n",
       "13                            0.010   0.543828  0.009510  0.295749  \n",
       "4                             0.001   0.544007  0.008164  0.295944  \n",
       "10                            0.001   0.544008  0.008252  0.295945  \n",
       "16                            0.001   0.544228  0.008017  0.296184  \n",
       "8                             0.001   0.544758  0.008063  0.296762  \n",
       "2                             0.001   0.544838  0.007734  0.296848  \n",
       "7                             0.010   0.545197  0.010686  0.297240  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork (mejor modelo en validación) -> rmse: 0.535, MSE: 0.286, MAE: 0.415, R2: 0.388\n"
     ]
    }
   ],
   "source": [
    "# --- Neural Network (MLP) ---\n",
    "mlp_pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", MLPRegressor(max_iter=500, random_state=42, early_stopping=True))\n",
    "])\n",
    "\n",
    "param_grid_mlp = {\n",
    "    \"model__hidden_layer_sizes\": [(64,), (128,64), (64,32)],\n",
    "    \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"model__learning_rate_init\": [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_mlp = GridSearchCV(\n",
    "    estimator=mlp_pipe,\n",
    "    param_grid=param_grid_mlp,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_mlp.fit(X_train, y_train)\n",
    "optimized_models[\"NeuralNetwork\"] = grid_mlp.best_estimator_\n",
    "print(f\"✅ NeuralNetwork - mejor params: {grid_mlp.best_params_}, rmse: {-grid_mlp.best_score_:.3f}\")\n",
    "\n",
    "mlp_cv = pd.DataFrame(grid_mlp.cv_results_)\n",
    "mlp_cv[\"rmse_mean\"] = -mlp_cv[\"mean_test_score\"]\n",
    "mlp_cv[\"rmse_std\"] = mlp_cv[\"std_test_score\"]\n",
    "mlp_cv[\"MSE_mean\"] = mlp_cv[\"rmse_mean\"] ** 2\n",
    "\n",
    "mlp_summary = mlp_cv[[\n",
    "    \"param_model__hidden_layer_sizes\",\n",
    "    \"param_model__alpha\",\n",
    "    \"param_model__learning_rate_init\",\n",
    "    \"rmse_mean\",\n",
    "    \"rmse_std\",\n",
    "    \"MSE_mean\"\n",
    "]].sort_values(by=\"rmse_mean\")\n",
    "\n",
    "display(mlp_summary.head(10))\n",
    "\n",
    "best_mlp = grid_mlp.best_estimator_\n",
    "y_pred_mlp = best_mlp.predict(X_val)\n",
    "\n",
    "mse_mlp = mean_squared_error(y_val, y_pred_mlp)\n",
    "rmse_mlp = np.sqrt(mse_mlp)\n",
    "mae_mlp = mean_absolute_error(y_val, y_pred_mlp)\n",
    "r2_mlp = r2_score(y_val, y_pred_mlp)\n",
    "\n",
    "print(\n",
    "    f\"NeuralNetwork (mejor modelo en validación) -> \"\n",
    "    f\"rmse: {rmse_mlp:.3f}, MSE: {mse_mlp:.3f}, MAE: {mae_mlp:.3f}, R2: {r2_mlp:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/NeuralNetwork_gridsearch_results.tex\n"
     ]
    }
   ],
   "source": [
    "export_df_to_latex(\n",
    "    df = rf_summary,  \n",
    "    filename = \"NeuralNetwork_gridsearch_results.tex\",\n",
    "    caption = \"Resultados del GridSearchCV para el modelo Neural Network.\",\n",
    "    label = \"tab:NeuralNetwork-gridsearch\",\n",
    "    bigTable = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "e8301b1a"
   },
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    \"Dummy\": models[\"Dummy\"],\n",
    "    \"LinearRegression\": models[\"LinearRegression\"],\n",
    "    \"LinearRegression_Lasso\": grid_lasso.best_estimator_,\n",
    "    \"LinearRegression_Ridge\": grid_ridge.best_estimator_,\n",
    "    **optimized_models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "fe48cf72",
    "outputId": "b33a95de-ba46-47fe-a7e9-c6d56ddc7154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando validación cruzada (Cross-Validation) en todos los modelos...\n",
      "→ Dummy\n",
      "→ LinearRegression\n",
      "→ LinearRegression_Lasso\n",
      "→ LinearRegression_Ridge\n",
      "→ DecisionTree\n",
      "→ RandomForest\n",
      "→ GradientBoosting\n",
      "→ NeuralNetwork\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>MSE_mean</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>R2_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.516694</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.267013</td>\n",
       "      <td>0.402559</td>\n",
       "      <td>0.427397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.517135</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.267485</td>\n",
       "      <td>0.401450</td>\n",
       "      <td>0.426432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.534196</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.285400</td>\n",
       "      <td>0.416790</td>\n",
       "      <td>0.387854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression_Ridge</td>\n",
       "      <td>0.541587</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.293350</td>\n",
       "      <td>0.421807</td>\n",
       "      <td>0.370851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.541591</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.293354</td>\n",
       "      <td>0.421811</td>\n",
       "      <td>0.370842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression_Lasso</td>\n",
       "      <td>0.542477</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.294314</td>\n",
       "      <td>0.423378</td>\n",
       "      <td>0.368782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.548191</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.300562</td>\n",
       "      <td>0.428031</td>\n",
       "      <td>0.355438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.683111</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.466694</td>\n",
       "      <td>0.546833</td>\n",
       "      <td>-0.000754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Modelo  rmse_mean  rmse_std  MSE_mean  MAE_mean   R2_mean\n",
       "6        GradientBoosting   0.516694  0.006335  0.267013  0.402559  0.427397\n",
       "5            RandomForest   0.517135  0.007516  0.267485  0.401450  0.426432\n",
       "7           NeuralNetwork   0.534196  0.005870  0.285400  0.416790  0.387854\n",
       "3  LinearRegression_Ridge   0.541587  0.005775  0.293350  0.421807  0.370851\n",
       "1        LinearRegression   0.541591  0.005762  0.293354  0.421811  0.370842\n",
       "2  LinearRegression_Lasso   0.542477  0.005674  0.294314  0.423378  0.368782\n",
       "4            DecisionTree   0.548191  0.006997  0.300562  0.428031  0.355438\n",
       "0                   Dummy   0.683111  0.007253  0.466694  0.546833 -0.000754"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Ejecutando validación cruzada (Cross-Validation) en todos los modelos...\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "\n",
    "for name, model in all_models.items():\n",
    "    print(f\"→ {name}\")\n",
    "\n",
    "    # Si el modelo ya es un Pipeline (best_estimator_), lo usamos tal cual.\n",
    "    # Si no, lo envolvemos con el preprocessor.\n",
    "    pipe = model if isinstance(model, Pipeline) else Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    # rmse NEGATIVO (sklearn lo devuelve negativo por convención de maximizar)\n",
    "    scores_rmse_neg = cross_val_score(\n",
    "        pipe, X, y,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv=kf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Convertimos a rmse positivo\n",
    "    scores_rmse = -scores_rmse_neg\n",
    "\n",
    "    # A partir de rmse podemos obtener MSE por fold\n",
    "    scores_mse = scores_rmse ** 2\n",
    "\n",
    "    # MAE (negativo)\n",
    "    scores_mae_neg = cross_val_score(\n",
    "        pipe, X, y,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=kf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    scores_mae = -scores_mae_neg\n",
    "\n",
    "    # R2\n",
    "    scores_r2 = cross_val_score(\n",
    "        pipe, X, y,\n",
    "        scoring=\"r2\",\n",
    "        cv=kf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv_results.append({\n",
    "        \"Modelo\": name,\n",
    "        \"rmse_mean\": np.mean(scores_rmse),\n",
    "        \"rmse_std\": np.std(scores_rmse),\n",
    "        \"MSE_mean\": np.mean(scores_mse),\n",
    "        \"MAE_mean\": np.mean(scores_mae),\n",
    "        \"R2_mean\": np.mean(scores_r2)\n",
    "    })\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results).sort_values(by=\"rmse_mean\")\n",
    "display(cv_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo LaTeX generado: Informe/tex/tables/cv_all_models_results.tex\n"
     ]
    }
   ],
   "source": [
    "export_df_to_latex(\n",
    "    df=cv_results_df,\n",
    "    filename=\"cv_all_models_results.tex\",\n",
    "    caption=r\"Resultados de validación cruzada (5-fold) para todos los modelos.\",\n",
    "    label=r\"tab:cv-all-models\",\n",
    "    bigTable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7e8de5b"
   },
   "source": [
    "## Load the test data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "073b1701",
    "outputId": "9b441c11-d14e-486a-cf53-7493a7bcf8b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15843708</td>\n",
       "      <td>Monoambiente en Barrio Norte</td>\n",
       "      <td>19787638</td>\n",
       "      <td>Pablo</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>-34.59053</td>\n",
       "      <td>-58.40898</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>03-11-2019</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9735218</td>\n",
       "      <td>Busco Roomate :)</td>\n",
       "      <td>38507726</td>\n",
       "      <td>Angela</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>-34.58633</td>\n",
       "      <td>-58.41312</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35682605</td>\n",
       "      <td>Betty´s home</td>\n",
       "      <td>100972248</td>\n",
       "      <td>Cecilia</td>\n",
       "      <td>Balvanera</td>\n",
       "      <td>-34.59979</td>\n",
       "      <td>-58.39340</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>03-11-2019</td>\n",
       "      <td>2.67</td>\n",
       "      <td>5</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9473906</td>\n",
       "      <td>Lovely Studio in Palermo</td>\n",
       "      <td>25602761</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>Recoleta</td>\n",
       "      <td>-34.59395</td>\n",
       "      <td>-58.41423</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>21-11-2019</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34155238</td>\n",
       "      <td>Cozy and comfortable apartment in Belgrano.</td>\n",
       "      <td>128766227</td>\n",
       "      <td>Maite</td>\n",
       "      <td>Colegiales</td>\n",
       "      <td>-34.56911</td>\n",
       "      <td>-58.45162</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10-11-2019</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         name    host_id host_name  \\\n",
       "0  15843708                 Monoambiente en Barrio Norte   19787638     Pablo   \n",
       "1   9735218                             Busco Roomate :)   38507726    Angela   \n",
       "2  35682605                                 Betty´s home  100972248   Cecilia   \n",
       "3   9473906                     Lovely Studio in Palermo   25602761   Mariano   \n",
       "4  34155238  Cozy and comfortable apartment in Belgrano.  128766227     Maite   \n",
       "\n",
       "  neighbourhood  latitude  longitude        room_type  minimum_nights  \\\n",
       "0      Recoleta -34.59053  -58.40898  Entire home/apt               2   \n",
       "1       Palermo -34.58633  -58.41312     Private room               1   \n",
       "2     Balvanera -34.59979  -58.39340  Entire home/apt               3   \n",
       "3      Recoleta -34.59395  -58.41423  Entire home/apt               3   \n",
       "4    Colegiales -34.56911  -58.45162  Entire home/apt               2   \n",
       "\n",
       "   number_of_reviews last_review  reviews_per_month  \\\n",
       "0                 26  03-11-2019               0.90   \n",
       "1                  0         NaN                NaN   \n",
       "2                  4  03-11-2019               2.67   \n",
       "3                 43  21-11-2019               0.89   \n",
       "4                 13  10-11-2019               2.12   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               1                74  \n",
       "1                               1                 0  \n",
       "2                               5               270  \n",
       "3                               1               142  \n",
       "4                               1               241  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando y guardando predicciones para Dummy...\n",
      "Guardado: pred_Dummy.csv\n",
      "Entrenando y guardando predicciones para LinearRegression...\n",
      "Guardado: pred_LinearRegression.csv\n",
      "Entrenando y guardando predicciones para LinearRegression_Lasso...\n",
      "Guardado: pred_LinearRegression_Lasso.csv\n",
      "Entrenando y guardando predicciones para LinearRegression_Ridge...\n",
      "Guardado: pred_LinearRegression_Ridge.csv\n",
      "Entrenando y guardando predicciones para DecisionTree...\n",
      "Guardado: pred_DecisionTree.csv\n",
      "Entrenando y guardando predicciones para RandomForest...\n",
      "Guardado: pred_RandomForest.csv\n",
      "Entrenando y guardando predicciones para GradientBoosting...\n",
      "Guardado: pred_GradientBoosting.csv\n",
      "Entrenando y guardando predicciones para NeuralNetwork...\n",
      "Guardado: pred_NeuralNetwork.csv\n",
      "Todas las predicciones fueron generadas y guardadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(base_path + \"test.csv\")\n",
    "display(test_df.head())\n",
    "\n",
    "# Mismas transformaciones que en train\n",
    "test_df[\"reviews_per_month\"] = test_df[\"reviews_per_month\"].fillna(0)\n",
    "test_df[\"last_review\"] = pd.to_datetime(test_df[\"last_review\"], errors=\"coerce\")\n",
    "test_df[\"days_since_last_review\"] = (pd.Timestamp(\"today\") - test_df[\"last_review\"]).dt.days\n",
    "test_df[\"days_since_last_review\"] = test_df[\"days_since_last_review\"].fillna(df[\"days_since_last_review\"].max())\n",
    "\n",
    "if is_Drive:\n",
    "    pred_folder = os.path.join(base_path, \"pred\")\n",
    "    os.makedirs(pred_folder, exist_ok=True)\n",
    "else:\n",
    "    pred_folder = \"pred\"\n",
    "    os.makedirs(pred_folder, exist_ok=True)\n",
    "\n",
    "for name, model in all_models.items():\n",
    "    print(f\"Entrenando y guardando predicciones para {name}...\")\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"model\", model)]) if not isinstance(model, Pipeline) else model\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    test_pred = pipe.predict(test_df.drop(columns=[\"id\"], errors=\"ignore\"))\n",
    "    test_pred = np.expm1(test_pred)  # revertimos log1p\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"price\": test_pred\n",
    "    })\n",
    "\n",
    "    filename = f\"pred_{name}.csv\"\n",
    "    save_path = os.path.join(pred_folder, filename)\n",
    "    submission.to_csv(save_path, index=False)\n",
    "    print(f\"Guardado: {filename}\")\n",
    "\n",
    "print(\"Todas las predicciones fueron generadas y guardadas correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
