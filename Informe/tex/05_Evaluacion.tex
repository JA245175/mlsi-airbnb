\newpage

\section{Evaluación y selección de modelos}

La evaluación siguió dos etapas:

\begin{enumerate}
    \item Validación inicial con hold-out 70/30 para iterar rápidamente sobre modelos y preseleccionar candidatos.
    \item Validación cruzada con \texttt{GridSearchCV} (5 pliegues) para seleccionar hiperparámetros y evaluar la robustez de los modelos preseleccionados. 
\end{enumerate}

Además, todas las métricas se calcularon sobre el precio transformado con \texttt{log1p} para mantener consistencia con el entrenamiento.

\subsection{Estrategia y métricas}

Se utilizó \texttt{train\_test\_split} con \texttt{random\_state=42} y, para la búsqueda de hiperparámetros, \texttt{GridSearchCV} con \texttt{KFold} de 5 pliegues y \texttt{n\_jobs=-1}. La métrica principal fue RMSE; también se monitorizaron MSE, MAE y R\textsuperscript{2}.

\subsection{Hiperparámetros óptimos y desempeño en la partición de validación}

\subsubsection{Laso}

\input{./tex/tables/Lasso_gridsearch_results.tex}

\subsubsection{Ridge}

\input{./tex/tables/Ridge_gridsearch_results.tex}

\subsubsection{Árbol de Decisión}

\input{./tex/tables/DecisionTreeRegressor_gridsearch_results.tex}

\subsubsection{Random Forest}

\input{./tex/tables/RandomForest_gridsearch_results.tex}


\subsubsection{Gradient Boosting}

\input{./tex/tables/GradientBoosting_gridsearch_results.tex}

\subsubsection{Red Neuronal (MLP)}

\input{./tex/tables/MLP_gridsearch_results.tex}


\subsection{Resultados Finales}

A continuación se presentan los mejores hiperparámetros encontrados para cada modelo junto con sus métricas en la partición de validación 70/30:

\input{./tex/tables/cv_results_all_models.tex}

\subsubsection{Síntesis de resultados}
\begin{itemize}
    \item \textbf{Hold-out 70/30} (Tabla \ref{tab:model-results-first-barrido}): Random Forest (RMSE 0.5533, MAE 0.4199, R\textsuperscript{2} 0.4281) lidera el desempeño, seguido por Gradient Boosting (RMSE 0.5649, MAE 0.4313, R\textsuperscript{2} 0.4040). Los modelos lineales (Linear Regression, Ridge, Lasso) muestran un rendimiento consistente con un RMSE cercano a 0.586. La Red Neuronal base comienza con un RMSE de 0.6006, mientras que el Árbol de Decisión sin optimizar presenta un sobreajuste severo o mal desempeño (RMSE 0.8009).
    \item \textbf{Validación cruzada (5 pliegues)} (Tabla \ref{tab:cv-all-models}): Se confirma la superioridad de Random Forest Optimizado, logrando el mejor RMSE promedio de 0.5604 ($\pm$ 0.0098) y un R\textsuperscript{2} de 0.4165. Gradient Boosting se mantiene competitivo (RMSE 0.5719), pero por debajo de Random Forest.
    \item \textbf{Mejoras por optimización}: La optimización de hiperparámetros fue crucial para el Árbol de Decisión, reduciendo su RMSE de 0.7955 a 0.6025. La Red Neuronal también mejoró significativamente (de 0.6178 a 0.5849), superando ligeramente a los modelos lineales. Random Forest mostró una mejora marginal con la optimización (0.5624 a 0.5604), lo que indica que su configuración base ya era bastante robusta.
    \item \textbf{Conclusión práctica}: Random Forest Optimizado es el candidato final seleccionado por su consistencia y menor error tanto en validación simple como cruzada. Los modelos lineales sirven como una base sólida y rápida, mientras que las redes neuronales requieren más ajuste para superar a los métodos de ensamble en este dataset tabular.
    \item El valor de \textbf{MSE} obtenido por los modelos en  \textit{Kaggle} fue de  11000.
\end{itemize}
