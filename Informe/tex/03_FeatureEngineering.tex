\newpage

\section{Feature Engineering}

Se desarrollaron procesos de transformación y selección de variables para optimizar el rendimiento de los modelos.

\lstinputlisting[language=Python, caption={Feature engineering: escalamos variables numéricas y codificamos las categóricas.}]{./code/featureEngineering.py}

\subsection{Manejo de variables categóricas}

Las variables categóricas (\texttt{neighbourhood}, \texttt{room\_type}) fueron transformadas utilizando \texttt{OneHotEncoder}. Se configuró para ignorar categorías desconocidas durante la validación/test (\texttt{handle\_unknown='ignore'}), lo cual es crucial para manejar posibles valores nuevos en el conjunto de prueba.


\subsection{Escalado de variables numéricas}

Las columnas numéricas se estandarizaron con el escalador estándar (\texttt{Standard\allowbreak Scaler}). Este paso se incluyó dentro de un \texttt{ColumnTransformer} para centrar y escalar cada variable en un solo paso y mantener la coherencia entre entrenamiento, validación y test.

\subsection{Creación de nuevas características}

Con la intención de enriquecer el conjunto de datos y capturar patrones relevantes, se implementaron las siguientes transformaciones:

\subsubsection{Procesamiento de Lenguaje Natural (NLP)}
La columna \texttt{name} fue procesada para extraer información semántica valiosa:
\begin{itemize}
    \item \textbf{Limpieza}: Se normalizó el texto a minúsculas y se eliminaron acentos y caracteres especiales utilizando la librería \texttt{unidecode}.
    \item \textbf{Palabras Clave}: Se crearon variables binarias (\texttt{has\_luxury\_keywords}, \texttt{is\_studio}, \texttt{is\_room}) detectando la presencia de términos específicos (e.g., "luxury", "premium", "studio", "loft") en el nombre del anuncio.
    \item \textbf{Similitud Semántica}: Se utilizaron \textit{embeddings} del modelo \texttt{all-MiniLM-\allowbreak L6-v2} de \texttt{Sentence\allowbreak Transformer}. Se calcularon las similitudes coseno entre el embedding del nombre de cada anuncio y los embeddings de tres conceptos objetivo: "Luxury/\allowbreak Premium", "Studio/\allowbreak Small" y "Room/\allowbreak Shared". Esto generó tres nuevas variables continuas: \texttt{sim\_luxury}, \texttt{sim\_studio} y \texttt{sim\_room}.
\end{itemize}

\subsubsection{Variables Geoespaciales}
Se calculó la distancia al centro de la ciudad (Obelisco) utilizando la fórmula de Haversine a partir de las coordenadas de latitud y longitud, generando la variable \texttt{distance\_to\_obelisco}.

\subsubsection{Nueva variable calculada}

Se creó la variable \texttt{precio\_medio\_barrio} que representa el precio promedio por barrio (\texttt{neighbourhood}) en el conjunto de entrenamiento. Esta variable captura tendencias locales de precios y se incorporó como una característica adicional en el modelo.

\subsubsection{Transformaciones Logarítmicas}
Se aplicó la transformación $\log(1+x)$ a nuevas variables con distribuciones muy sesgadas para reducir el impacto de valores extremos de :

\begin{itemize}
    \item \texttt{minimum\_nights}
    \item \texttt{number\_of\_reviews}
    \item \texttt{reviews\_per\_month}
    \item \texttt{availability\_365}
    \item \texttt{calculated\_host\_listings\_count}
    \item \texttt{days\_since\_last\_review}
\end{itemize}

\subsection{Gestión de data leakage}

Para evitar la fuga de información (\textit{data leakage}), todas las transformaciones (escalado estándar para numéricas y codificación one-hot para categóricas) se implementaron dentro de \texttt{Pipelines} de scikit-learn. Esto asegura que los parámetros de transformación (como la media y desviación estándar del \texttt{StandardScaler}) se aprendan únicamente del conjunto de entrenamiento y se apliquen consistentemente a los conjuntos de validación y prueba.
